{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaZ+mNKmCVIeLpEfVmo6k+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/scikitTOpytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scikit-learn vers pytorch\n",
        "\n",
        "L'objet de ce petit notebook est de montrer comment on peut implémenter les MLP de scikit-learn en pytorch (sachant que pytorch permet d'utiliser n'importe quel type de réseau de neurones et pas nécessairement des MLP).\n",
        "\n",
        "Le code du MLP pytorch est bien proche de celui de scikit-learning https://github.com/scikit-learn/scikit-learn/tree/main/sklearn/neural_network (mais il y a des choses différentes comme le raisonnement en epoch etc).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KOPAKmVqe9Xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MNIST\n",
        "Je propose d'utiliser le jeu de données MNIST pour effectuer la comparaison.\n",
        "\n",
        "Pour cela, récupérons le dataset à l'aide de torchvision, puis convertissons le en format vectoriel pour scikit-learn.\n",
        "\n",
        "(Notons, que le dataset torchvision peut directement être donnée à un dataloader torchvision qui fait des paquets - ce qui est pertinent vu que l'optimisation n'est pas globale - cependant c'est le format scikit qui veut ça.)"
      ],
      "metadata": {
        "id": "xD4Is24vg8Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import torch\n",
        "import torchvision\n",
        "import sklearn\n",
        "\n",
        "mnisttrain = torchvision.datasets.MNIST(\"./mnist\",train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "mnisttest = torchvision.datasets.MNIST(\"./mnist\",train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "Xtrain,Ytrain = torch.zeros(len(mnisttrain),28,28),torch.zeros(len(mnisttrain))\n",
        "Xtest,Ytest = torch.zeros(len(mnisttest),28,28),torch.zeros(len(mnisttest))\n",
        "\n",
        "for i in range(Xtrain.shape[0]):\n",
        "  Xtrain[i],Ytrain[i] = mnisttrain[i]\n",
        "for i in range(Xtest.shape[0]):\n",
        "  Xtest[i],Ytest[i] = mnisttest[i]\n",
        "\n",
        "Xtrain,Xtest = Xtrain.flatten(1),Xtest.flatten(1)\n"
      ],
      "metadata": {
        "id": "l4RqFC7UhOzA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MNIST avec scikit-learn"
      ],
      "metadata": {
        "id": "Q406t6pRgtlQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzH3Zr5Xef22",
        "outputId": "cf40cefa-e063-4c75-cd09-979fd94207f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9802"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(random_state=1, max_iter=300)\n",
        "clf.fit(Xtrain.numpy(),Ytrain.numpy())\n",
        "clf.score(Xtest.numpy(),Ytest.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Même chose avec pytorch\n"
      ],
      "metadata": {
        "id": "mKb1-NdSoeAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self,hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, nbepoches=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000):\n",
        "    super(MLP, self).__init__()\n",
        "    self.hidden_layer_sizes = hidden_layer_sizes\n",
        "    self.activation = activation\n",
        "    self.solver = solver\n",
        "    self.alpha = alpha\n",
        "    self.batch_size = 'auto'\n",
        "    self.learning_rate = learning_rate\n",
        "    self.learning_rate_init=learning_rate_init\n",
        "    self.power_t=power_t\n",
        "    self.nbepoches=nbepoches\n",
        "    self.shuffle=shuffle\n",
        "    self.random_state=random_state\n",
        "    self.tol=tol\n",
        "    self.verbose=verbose\n",
        "    self.warm_start=warm_start\n",
        "    self.momentum=momentum\n",
        "    self.nesterovs_momentum=nesterovs_momentum\n",
        "    self.early_stopping=early_stopping\n",
        "    self.validation_fraction=validation_fraction\n",
        "    self.beta_1=beta_1\n",
        "    self.beta_2=beta_2\n",
        "    self.epsilon=epsilon\n",
        "    self.n_iter_no_change=n_iter_no_change\n",
        "    self.max_fun=max_fun\n",
        "\n",
        "    if activation!='relu' or solver!='adam':\n",
        "      print(\"ben faut le faire XD\")\n",
        "      quit()\n",
        "    self.linears = None # be defined after\n",
        "\n",
        "  def forward(self,x):\n",
        "    for i in range(len(self.linears)):\n",
        "      x = self.linears[i](x)\n",
        "      x = torch.nn.functional.leaky_relu(x)\n",
        "    return x\n",
        "\n",
        "  def fit(self,X,Y):\n",
        "    nbclass = int(torch.max(Y).item())+1\n",
        "    print(\"nbclass\",nbclass)\n",
        "    dim = X.shape[1]\n",
        "    print(\"dim\",dim)\n",
        "\n",
        "    if isinstance(self.hidden_layer_sizes,int):\n",
        "      self.hidden_layer_sizes = [self.hidden_layer_sizes]\n",
        "    self.linears = torch.nn.ModuleList([torch.nn.Linear(dim, self.hidden_layer_sizes[0])])\n",
        "    for i in range(1,len(self.hidden_layer_sizes)):\n",
        "      self.linears.append(torch.nn.Linear(self.hidden_layer_sizes[i-1], self.hidden_layer_sizes[i]))\n",
        "    self.linears.append(torch.nn.Linear(self.hidden_layer_sizes[-1], nbclass))\n",
        "\n",
        "    solver =torch.optim.Adam(self.parameters(), lr=self.learning_rate_init)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(X,Y)\n",
        "    if isinstance(self.batch_size, str):\n",
        "      self.batch_size = 512 # ;-)\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset,batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "    for tmp in range(self.max_iter):\n",
        "      for x,y in dataloader:\n",
        "        z = self.forward(x)\n",
        "        loss = criterion(z, y.long())\n",
        "        solver.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.parameters(), 10)\n",
        "        solver.step()\n",
        "\n",
        "  def predict(self,X):\n",
        "    with torch.no_grad():\n",
        "      Z = self.forward(X) #assume it will not explode ram...\n",
        "      _,Z = torch.max(Z,dim=1)\n",
        "      return Z\n",
        "\n",
        "  def score(self,X,Y):\n",
        "    Z = self.predict(X)\n",
        "    return torch.sum(Z==Y)/Y.shape[0]\n"
      ],
      "metadata": {
        "id": "fRTLIWbjohv3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLP(random_state=1, nbepoches=30)\n",
        "clf.fit(Xtrain,Ytrain)\n",
        "clf.score(Xtest,Ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FAB6OnJo9He",
        "outputId": "69f7f909-2e9f-4293-9b4b-f3adaa74d0b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nbclass 10\n",
            "dim 784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9758)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}