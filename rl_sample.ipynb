{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMK3IPlLzdp6wH/DTBAUik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/rl_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium\n",
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\"\n",
        "!pip install schedulefree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rloprxr9IZbr",
        "outputId": "8b76dac9-04f7-49ec-fd79-ed6580578b4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1)\n",
            "Requirement already satisfied: schedulefree in /usr/local/lib/python3.10/dist-packages (1.2.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K4RF9azGJ4RN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gymnasium\n",
        "import schedulefree\n",
        "\n",
        "GAMMA=0.99\n",
        "\n",
        "class MemoryBuffer:\n",
        "    def __init__(self):\n",
        "        self.i = 0\n",
        "        self.full = False\n",
        "\n",
        "        L=50000\n",
        "        self.s = torch.zeros(L,8)\n",
        "        self.a = torch.zeros(L,4)\n",
        "        self.r = torch.zeros(L)\n",
        "        self.s_ = torch.zeros(L,8)\n",
        "        self.f = torch.zeros(L)\n",
        "\n",
        "    def push(self, s, a, r, s_, f):\n",
        "        self.s[self.i] = s\n",
        "        self.a[self.i][a] = 1\n",
        "        self.r[self.i] = r\n",
        "        self.s_[self.i] = s_\n",
        "        self.f[self.i] = 1-f\n",
        "        self.i += 1\n",
        "        if self.i >= self.r.shape[0]:\n",
        "            self.full = True\n",
        "            self.i = 0\n",
        "\n",
        "    def getBatch(self, B=64):\n",
        "        if self.full:\n",
        "            I = list((torch.rand(B) * self.r.shape[0]).long())\n",
        "        else:\n",
        "            I = list((torch.rand(B) * self.i).long())\n",
        "        return (self.s[I], self.a[I], self.r[I], self.s_[I], self.f[I])\n",
        "\n",
        "def trial(env,agent, T, memory):\n",
        "    totalR = 0\n",
        "    s, info = env.reset()\n",
        "    s = torch.Tensor(s)\n",
        "    for _ in range(1000):\n",
        "        a = agent.sample(s,T)\n",
        "        s_, r, terminated, truncated, info = env.step(a)\n",
        "        s_ = torch.Tensor(s_)\n",
        "\n",
        "        memory.push(s,a,r,s_,terminated or truncated)\n",
        "        totalR+=r\n",
        "        if terminated or truncated:\n",
        "            return totalR\n",
        "        else:\n",
        "            s = s_\n",
        "\n",
        "def train(agent,T,memory,nbstep):\n",
        "    optimizer = schedulefree.AdamWScheduleFree(agent.parameters(), lr=0.001)\n",
        "\n",
        "    meanloss = torch.zeros(nbstep)\n",
        "    for step in range(nbstep):\n",
        "        B = memory.getBatch()\n",
        "        S, A, R, S_,F = B\n",
        "\n",
        "        Q = agent.Q(S)\n",
        "        QA = (Q * A).sum(1)\n",
        "        Q_ = agent.V(S_,T)\n",
        "        loss = ((GAMMA * Q_ * F + R - QA)**2).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            meanloss[step] = loss.clone()\n",
        "    return float(meanloss.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def leakyRelu(x):\n",
        "    return torch.minimum(x,x*0.2)\n",
        "\n",
        "class Block(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Block,self).__init__()\n",
        "\n",
        "        self.f1 =torch.nn.Linear(24,8)\n",
        "        self.f2 =torch.nn.Linear(8,24)\n",
        "        self.f3 =torch.nn.Linear(24,16)\n",
        "\n",
        "    def forward(self,x):\n",
        "        f = leakyRelu(self.f1(x))\n",
        "        f = leakyRelu(self.f2(f))\n",
        "        f = leakyRelu(self.f3(f))\n",
        "\n",
        "        tmp = torch.zeros(x.shape[0],8)\n",
        "        f = torch.cat([tmp,f],dim=1)\n",
        "        return x+f\n",
        "\n",
        "\n",
        "class LunarAgent(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LunarAgent,self).__init__()\n",
        "\n",
        "        self.b1 = Block()\n",
        "        self.b2 = Block()\n",
        "        self.b3 = Block()\n",
        "        self.b4 = Block()\n",
        "        self.b5 = Block()\n",
        "        self.b6 = Block()\n",
        "        self.b7 = Block()\n",
        "\n",
        "        self.A =torch.nn.Linear(24,4)\n",
        "\n",
        "    def forward(self,x):\n",
        "        code = torch.zeros(x.shape[0],16)\n",
        "        x = torch.cat([x,code],dim=1)\n",
        "\n",
        "        x = self.b1(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.b4(x)\n",
        "        x = self.b5(x)\n",
        "        x = self.b6(x)\n",
        "        x = self.b7(x)\n",
        "\n",
        "        return self.A(x)\n",
        "\n",
        "    def Q(self,x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def pi(self,Q,T):\n",
        "        return torch.nn.functional.softmax(T*Q,dim=1)\n",
        "\n",
        "    def V(self,x,T):\n",
        "        Q =self.Q(x)\n",
        "        pi = self.pi(Q,T)\n",
        "        return (Q*pi).sum(1)\n",
        "\n",
        "    def sample(self,x,T):\n",
        "        with torch.no_grad():\n",
        "            pi = self.pi(self.Q(x.view(1,-1)),T)\n",
        "            return int(torch.multinomial(pi, num_samples=1))"
      ],
      "metadata": {
        "id": "b3Bk10nV2gYi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"LunarLander-v3\")\n",
        "\n",
        "T = 0.25\n",
        "agent = LunarAgent()\n",
        "\n",
        "for j in range(10):\n",
        "    T = 1.3*T\n",
        "    if T>1.5:\n",
        "        memory = MemoryBuffer()\n",
        "        for _ in range(30):\n",
        "            trial(env,agent,T,memory)\n",
        "    for i in range(20+j*5):\n",
        "        v = trial(env,agent,T,memory)\n",
        "        l = train(agent,T,memory, nbstep=100+20*j)\n",
        "        if i%5==0:\n",
        "            print(\"\\t\",v,l)\n",
        "    tot = 0\n",
        "    for _ in range(30):\n",
        "        tot+=trial(env,agent,T,memory)\n",
        "    print(T,tot/30)\n"
      ],
      "metadata": {
        "id": "pgzIHX3nNIWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "972c8481-1310-4c28-8bcc-0c81bb6c10ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t -211.9193267100821 140.1090087890625\n",
            "\t -347.62495157637306 15.792109489440918\n",
            "\t -81.39771774836467 10.606745719909668\n",
            "\t -361.10400774616386 9.039100646972656\n",
            "0.35 -143.03772432824124\n",
            "\t -267.6278156205011 16.52506446838379\n",
            "\t -61.314386529326846 9.003512382507324\n",
            "\t -119.36474019174743 6.102186679840088\n",
            "\t -117.87790837391309 5.420865058898926\n",
            "\t -96.81846960902439 6.345512390136719\n",
            "0.48999999999999994 -111.75985960088568\n",
            "\t -219.13100086167472 10.215813636779785\n",
            "\t -57.59028893787283 7.810074806213379\n",
            "\t -92.70094242732058 6.986778736114502\n",
            "\t -76.13936443465332 7.206244945526123\n",
            "\t -80.36913743460899 6.9672932624816895\n",
            "\t -87.0052326514288 5.021262168884277\n",
            "0.6859999999999998 -94.8553551446476\n",
            "\t -63.96503796850151 5.250551700592041\n",
            "\t -90.19385198202752 4.089931964874268\n",
            "\t -85.80880746247459 3.295361042022705\n",
            "\t -80.34869231495858 3.590965509414673\n",
            "\t -92.27028194398527 2.588238477706909\n",
            "\t -48.425613225193715 2.8561806678771973\n",
            "\t -88.20360997034535 3.207838535308838\n",
            "0.9603999999999997 -63.671461273648085\n",
            "\t -51.41822435520753 3.105055809020996\n",
            "\t -14.748461373132272 2.508492946624756\n",
            "\t -58.96475797424051 2.4390335083007812\n",
            "\t -48.04813948922518 2.127854108810425\n",
            "\t 23.647708123813487 2.7675180435180664\n",
            "\t -67.80656258751851 3.020808696746826\n",
            "\t 22.244060372706443 2.7804758548736572\n",
            "\t -70.72888696975664 2.478304147720337\n",
            "1.3445599999999995 -35.424574802088834\n",
            "\t -51.57658107877891 2.9066665172576904\n",
            "\t 30.777356555420454 2.7133657932281494\n",
            "\t -5.838834361736801 5.570807933807373\n",
            "\t -19.863348545089153 2.994382619857788\n",
            "\t 84.9462165035788 6.36506986618042\n",
            "\t 21.412863437623628 7.233494281768799\n",
            "\t 33.46610315599588 7.298951148986816\n",
            "\t -5.258625807850805 8.87890911102295\n",
            "\t -16.33965262707865 6.427906036376953\n",
            "1.8823839999999992 20.38135113485363\n",
            "\t 127.5743763510625 8.590348243713379\n",
            "\t 147.2059420013875 5.724886417388916\n",
            "\t -239.38468058328394 6.125138759613037\n",
            "\t 35.79166849728554 9.884672164916992\n",
            "\t 78.20209016132051 10.912103652954102\n",
            "\t -238.42821375031468 6.502333641052246\n",
            "\t -183.87716218002697 9.712658882141113\n",
            "\t -249.82699472223325 8.72977352142334\n",
            "\t -54.528664654320295 11.869550704956055\n",
            "\t 16.05474244140845 8.91950798034668\n",
            "2.635337599999999 -97.02608499120906\n",
            "\t -251.7576957544032 12.527198791503906\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3cf27c41cb6b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-1e0938d18064>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(agent, T, memory, nbstep)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}