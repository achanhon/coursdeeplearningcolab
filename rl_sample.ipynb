{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS3Cz9erOLvoMlUnYKGems",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/rl_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium\n",
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\""
      ],
      "metadata": {
        "id": "Rloprxr9IZbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4RF9azGJ4RN"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import gymnasium\n",
        "\n",
        "class StateSampler:\n",
        "  def __init__(self,memory):\n",
        "    self.memory = memory\n",
        "    w = [t for t,_,_,_,_,_,_ in memory]\n",
        "    w = torch.Tensor(w)+1\n",
        "    self.w = w/float(w.sum())\n",
        "\n",
        "  def get(self,n):\n",
        "    I = torch.multinomial(self.w, n, replacement=True)\n",
        "    return torch.stack(memory[I][2],dim=0)\n",
        "\n",
        "class TransitionSampler:\n",
        "  def __init__(self,memory):\n",
        "    self.memory = memory\n",
        "    w = [totR for _,totR,_,_,_,_,_ in memory]\n",
        "    w = torch.Tensor(w)*0.1\n",
        "    self.w = torch.nn.functional.softmax(w,dim=0)\n",
        "\n",
        "  def get(self,n):\n",
        "    I = torch.multinomial(self.w, n, replacement=True)\n",
        "    return torch.stack(memory[I][2:],dim=0)\n",
        "\n",
        "def tokenf(f):\n",
        "  out = torch.zeros(7):\n",
        "  out[0]=f\n",
        "  if -0.001<=f<=0.001\n",
        "    out[1]=0\n",
        "  else:\n",
        "    if f<=0:\n",
        "      out[1]=-1\n",
        "    else\n",
        "      out[1]=1\n",
        "  f = int(abs(f)*32)\n",
        "  for i in range(5):\n",
        "    out[i+2] = f%2\n",
        "    f = f//2\n",
        "  return f\n",
        "\n",
        "def tokens(s):\n",
        "  out = [token(float(s[i])) for i in range(6)]\n",
        "  out = out+[torch.Tensor([float(s[6]),float(s[7])])]\n",
        "  return torch.cat(out,dim=0)\n",
        "\n",
        "def trial(env,agent,eps):\n",
        "  s, _ = env.reset(seed=0)\n",
        "  totR,s,traj =0, tokens(s),[]\n",
        "  agent.eval().cpu()\n",
        "  for _ in range(3000):\n",
        "    if random.random()<eps:\n",
        "      a = int(random.random()*4)\n",
        "    else:\n",
        "      _,a = agent(s.view(1,-1)).max(1)\n",
        "      a = int(a)\n",
        "\n",
        "    s_, r, terminated, truncated, _ = env.step(a)\n",
        "    s_,totR,a = tokens(s_),totR+r,torch.eye(4)[a]\n",
        "    traj.append((s,a,r,s_))\n",
        "\n",
        "    if terminated or truncated:\n",
        "      traj = [[totR,s,a,r,s_] for (s,a,r,s_) in traj]\n",
        "      for i in range(len(traj)-1):\n",
        "        traj[i].append(traj[i+1][2])\n",
        "      traj[-1].append(torch.zeros(4))\n",
        "      return totR,traj\n",
        "    else:\n",
        "      s = s_\n",
        "\n",
        "def learnQ(agent,optimizer, batchS,batchT):\n",
        "  Gamma=0.999\n",
        "  batchT = [obj.cuda() for obj in batchT]\n",
        "  S,R,A,S_,R_ = batchT\n",
        "\n",
        "  X = torch.cat([batchS.cuda(),S,S_],dim=0)\n",
        "  Q = agent(X)# group state for batch norm\n",
        "\n",
        "  reg = Q.mean()\n",
        "\n",
        "  QA,QA_ = Q[:S.shape[0]],Q[S.shape[0]:]\n",
        "  bellman = torch.nn.functional.relu(Gamma*QA_+R-QA)\n",
        "  bellman = (bellman**2).mean()\n",
        "\n",
        "  loss = bellman+0.01*reg\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return float(loss)\n",
        "\n",
        "def train(agent, optimizer,memory,n)\n",
        "  ss = StateSampler(memory)\n",
        "  ts = TransitionSampler(memory)\n",
        "  for _ in range(n):\n",
        "    losses = []\n",
        "    for _ in range(20):\n",
        "      batchS = ss.get(256)\n",
        "      batchT = ts.get(256)\n",
        "      losses.append(learnQ(agent,optimizer,batchS,batchT))\n",
        "    print(sum(losses)/20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaledLinear(torch.nn.Module):\n",
        "  def __init__(self, Din, Dout):\n",
        "    super(ScaledLinear, self).__init__()\n",
        "    self.l = torch.nn.Linear(Din, Dout, bias=False)\n",
        "    self.bn = torch.nn.BatchNorm1d(Dout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn(self.l(x))\n",
        "    return torch.nn.functional.relu(x)\n",
        "\n",
        "class LunarAgent(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LunarAgent,self).__init__()\n",
        "\n",
        "    self.l1 = ScaledLinear(44,256)\n",
        "    self.l2 = ScaledLinear(256,128)\n",
        "    self.l3 = ScaledLinear(44+128,256)\n",
        "    self.l4 = ScaledLinear(256,256)\n",
        "    self.l5 = ScaledLinear(44+256,512)\n",
        "    self.final =torch.nn.Linear(512,4)\n",
        "\n",
        "  def forward(self,x):\n",
        "    f = self.l1(x)\n",
        "    f = self.l2(f)\n",
        "    f = self.l3(torch.cat([x,f],dim=1))\n",
        "    f = self.l4(f)\n",
        "    f = self.l5(torch.cat([x,f],dim=1))\n",
        "    return self.final(f)\n"
      ],
      "metadata": {
        "id": "b3Bk10nV2gYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"LunarLander-v3\", continuous=False,enable_wind=False)\n",
        "\n",
        "T = 0.3\n",
        "agent = LunarAgent()\n",
        "SEUIL = 0.\n",
        "for _ in range(100):\n",
        "    SEUIL+=trial(env,agent,T)\n",
        "SEUIL = SEUIL/100\n",
        "\n",
        "for j in range(20):\n",
        "    memory = MemoryBuffer()\n",
        "    for _ in range(5):\n",
        "        trial(env,agent,T,memory,seed=42)\n",
        "    for i in range(10):\n",
        "        trial(env,agent,T,memory,seed=i)\n",
        "    for _ in range(35):\n",
        "        trial(env,agent,T,memory)\n",
        "\n",
        "    for _ in range(10+j*2):\n",
        "        v = trial(env,agent,T,memory)\n",
        "        l = train(agent,T,memory, nbstep=100+10*j)\n",
        "        print(\"\\t\",v,l)\n",
        "\n",
        "    tot = 0\n",
        "    for _ in range(100):\n",
        "        tot+=trial(env,agent,T)\n",
        "    tot = tot/100\n",
        "    print(j,T,tot)\n",
        "    if SEUIL<tot:\n",
        "        T = 1.2*T\n",
        "        SEUIL = tot\n"
      ],
      "metadata": {
        "id": "pgzIHX3nNIWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}