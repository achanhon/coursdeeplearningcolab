{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwebPkI2555Rj9XVbeeauu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/rl_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium\n",
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\""
      ],
      "metadata": {
        "id": "Rloprxr9IZbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4RF9azGJ4RN"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import gymnasium\n",
        "\n",
        "class StateSampler:\n",
        "  def __init__(self,memory):\n",
        "    self.memory = memory\n",
        "    w = [t for t,_,_,_,_,_,_ in memory]\n",
        "    w = torch.Tensor(w)+1\n",
        "    self.w = w/float(w.sum())\n",
        "\n",
        "  def get(self,n):\n",
        "    I = torch.multinomial(self.w, n, replacement=True)\n",
        "    return torch.stack(memory[I][2],dim=0)\n",
        "\n",
        "class TransitionSampler:\n",
        "  def __init__(self,memory):\n",
        "    self.memory = memory\n",
        "    w = [totR for _,totR,_,_,_,_,_ in memory]\n",
        "    w = torch.Tensor(w)*0.1\n",
        "    self.w = torch.nn.functional.softmax(w,dim=0)\n",
        "\n",
        "  def get(self,n):\n",
        "    I = torch.multinomial(self.w, n, replacement=True)\n",
        "    return torch.stack(memory[I][2:],dim=0)\n",
        "\n",
        "def tokenf(f):\n",
        "  out = torch.zeros(7):\n",
        "  out[0]=f\n",
        "  if -0.001<=f<=0.001\n",
        "    out[1]=0\n",
        "  else:\n",
        "    if f<=0:\n",
        "      out[1]=-1\n",
        "    else\n",
        "      out[1]=1\n",
        "  f = int(abs(f)*32)\n",
        "  for i in range(5):\n",
        "    out[i+2] = f%2\n",
        "    f = f//2\n",
        "  return f\n",
        "\n",
        "def tokens(s):\n",
        "  out = [token(float(s[i])) for i in range(6)]\n",
        "  out = out+[torch.Tensor([float(s[6]),float(s[7])])]\n",
        "  return torch.cat(out,dim=0)\n",
        "\n",
        "def trial(env,agent,eps):\n",
        "    s, _ = env.reset(seed=0)\n",
        "    totR,s,traj =0, tokens(s),[]\n",
        "    agent.eval().cpu()\n",
        "    for _ in range(3000):\n",
        "        if random.random()<eps:\n",
        "          a = int(random.random()*4)\n",
        "        else:\n",
        "          _,a = agent(s.view(1,-1)).max(1)\n",
        "          a = int(a)\n",
        "\n",
        "        s_, r, terminated, truncated, _ = env.step(a)\n",
        "        s_,totR,a = tokens(s_),totR+r,torch.eye(4)[a]\n",
        "        traj.append((s,a,r,s_))\n",
        "\n",
        "        if terminated or truncated:\n",
        "            traj = [[totR,s,a,r,s_] for (s,a,r,s_) in traj]\n",
        "            for i in range(len(traj)-1):\n",
        "              traj[i].append(traj[i+1][3])\n",
        "            traj[-1].append(torch.zeros(4))\n",
        "            return totR,traj\n",
        "        else:\n",
        "            s = s_\n",
        "\n",
        "def train(agent,T,memory,nbstep):\n",
        "    optimizer = schedulefree.AdamWScheduleFree(agent.parameters(), lr=0.001)\n",
        "\n",
        "    meanloss = torch.zeros(nbstep)\n",
        "    for step in range(nbstep):\n",
        "        B = memory.getBatch()\n",
        "        S, A, R, S_,F = B\n",
        "\n",
        "        Q = agent.Q(S)\n",
        "        QA = (Q * A).sum(1)\n",
        "        Q_ = agent.V(S_,T)\n",
        "        loss = ((GAMMA * Q_ * F + R - QA)**2).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            meanloss[step] = loss.clone()\n",
        "    return float(meanloss.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Block,self).__init__()\n",
        "\n",
        "        self.strongR = torch.nn.LeakyReLU(negative_slope=0.1)\n",
        "        self.weakR = torch.nn.LeakyReLU(negative_slope=0.5)\n",
        "        self.f1 =torch.nn.Linear(24,8)\n",
        "        self.f2 =torch.nn.Linear(8,8)\n",
        "        self.f3 =torch.nn.Linear(8,8)\n",
        "        self.f4 =torch.nn.Linear(8,16)\n",
        "\n",
        "    def forward(self,x):\n",
        "        f = self.strongR(self.f1(x))\n",
        "        f = f+self.strongR(self.f2(f))\n",
        "        f = f+self.strongR(self.f3(f))\n",
        "        f = self.weakR(self.f4(f))\n",
        "\n",
        "        tmp = torch.zeros(x.shape[0],8)\n",
        "        f = torch.cat([tmp,f],dim=1)\n",
        "        return x+f\n",
        "\n",
        "\n",
        "class LunarAgent(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LunarAgent,self).__init__()\n",
        "\n",
        "        self.b1 = Block()\n",
        "        self.b2 = Block()\n",
        "        self.b3 = Block()\n",
        "        self.b4 = Block()\n",
        "        self.b5 = Block()\n",
        "        self.b6 = Block()\n",
        "        self.b7 = Block()\n",
        "        self.b8 = Block()\n",
        "        self.b9 = Block()\n",
        "\n",
        "        self.A =torch.nn.Linear(24,4)\n",
        "\n",
        "    def forward(self,x):\n",
        "        code = torch.zeros(x.shape[0],16)\n",
        "        x = torch.cat([x,code],dim=1)\n",
        "\n",
        "        x = self.b1(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.b4(x)\n",
        "        x = self.b5(x)\n",
        "        x = self.b6(x)\n",
        "        x = self.b7(x)\n",
        "        x = self.b8(x)\n",
        "        x = self.b9(x)\n",
        "\n",
        "        return self.A(x)\n",
        "\n",
        "    def Q(self,x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def pi(self,Q,T):\n",
        "        Q = Q-Q.mean(1).view(-1,1)\n",
        "        # it does not change anything from mathematical point of view\n",
        "        # but it is numerically better\n",
        "        return torch.nn.functional.softmax(T*Q,dim=1)\n",
        "\n",
        "    def V(self,x,T):\n",
        "        Q =self.Q(x)\n",
        "        pi = self.pi(Q,T)\n",
        "        return (Q*pi).sum(1)\n",
        "\n",
        "    def sample(self,x,T):\n",
        "        with torch.no_grad():\n",
        "            pi = self.pi(self.Q(x.view(1,-1)),T)\n",
        "            return int(torch.multinomial(pi, num_samples=1))"
      ],
      "metadata": {
        "id": "b3Bk10nV2gYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"LunarLander-v3\", continuous=False, gravity=-8.0,enable_wind=False)\n",
        "\n",
        "T = 0.3\n",
        "agent = LunarAgent()\n",
        "SEUIL = 0.\n",
        "for _ in range(100):\n",
        "    SEUIL+=trial(env,agent,T)\n",
        "SEUIL = SEUIL/100\n",
        "\n",
        "for j in range(20):\n",
        "    memory = MemoryBuffer()\n",
        "    for _ in range(5):\n",
        "        trial(env,agent,T,memory,seed=42)\n",
        "    for i in range(10):\n",
        "        trial(env,agent,T,memory,seed=i)\n",
        "    for _ in range(35):\n",
        "        trial(env,agent,T,memory)\n",
        "\n",
        "    for _ in range(10+j*2):\n",
        "        v = trial(env,agent,T,memory)\n",
        "        l = train(agent,T,memory, nbstep=100+10*j)\n",
        "        print(\"\\t\",v,l)\n",
        "\n",
        "    tot = 0\n",
        "    for _ in range(100):\n",
        "        tot+=trial(env,agent,T)\n",
        "    tot = tot/100\n",
        "    print(j,T,tot)\n",
        "    if SEUIL<tot:\n",
        "        T = 1.2*T\n",
        "        SEUIL = tot\n"
      ],
      "metadata": {
        "id": "pgzIHX3nNIWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}