{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfoAK6cZTSirNn2t2cMTNH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d6vD1dKKgOH0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Game:\n",
        "  def __init__(self,other=None):\n",
        "    self.A = [(0,1),(-1,0),(1,0),(0,0),(0,2)]\n",
        "    if other is None:\n",
        "      self.t = 0\n",
        "      self.f=False\n",
        "      self.p = (1,0)\n",
        "      self.road = (torch.rand(3,60)<0.05).half()\n",
        "      self.road[:,0:2]=0\n",
        "    else:\n",
        "      self.p,self.t,self.f,self.road = other\n",
        "\n",
        "  def copy(self):\n",
        "    return Game((self.p,self.t,self.f,self.road))\n",
        "\n",
        "  def getVisibleState(self):\n",
        "    return (self.p[0],self.p[1]-self.t), self.road[:,self.t:self.t+7], self.f\n",
        "\n",
        "  def getVisibleStateString(self):\n",
        "    p,road = self.getVisibleState()\n",
        "    string_parts = []\n",
        "    for r in range(3):\n",
        "      for c in range(7):\n",
        "        if road[r][c]==1:\n",
        "          string_parts.append(\"o\")\n",
        "        else:\n",
        "          string_parts.append(\" \")\n",
        "        if r==p[0] and c==p[1]:\n",
        "          string_parts[-1]=\"x\"\n",
        "      string_parts.append(\"\\n\")\n",
        "    return \"----------\\n\"+\"\".join(string_parts)+\"----------\"\n",
        "\n",
        "  def update(self,a):\n",
        "    assert not self.f, print(\"update a final state\")\n",
        "    dr,dc = self.A[a]\n",
        "    p = self.p\n",
        "\n",
        "    # remove forbidden action\n",
        "    if p[1]==self.t and dc<1:\n",
        "      dr,dc = 0,1\n",
        "    if p[0]+dr<0:\n",
        "      dr,dc = 0,1\n",
        "    if p[0]+dr>2:\n",
        "      dr,dc=0,1\n",
        "    if p[1]+dc>self.t+5:\n",
        "      dr,dc = 0,1\n",
        "\n",
        "    if self.road[p[0]+dr][p[1]+dc]==1:\n",
        "      self.f = True\n",
        "      return -1\n",
        "    if dc==2 and self.road[p[0]][p[1]+1]==1:\n",
        "      self.f = True\n",
        "      return -1\n",
        "\n",
        "    self.p = (p[0]+dr,p[1]+dc)\n",
        "    self.t = self.t+1\n",
        "    if self.t==50:\n",
        "      self.f = True\n",
        "    return 0.06"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RL(torch.nn.Module):\n",
        "  def toTensor(self,x):\n",
        "    z = torch.zeros(3,3,7)\n",
        "    p,road,f = x\n",
        "    if f:\n",
        "      return z\n",
        "    z[2,:,:]=1\n",
        "    z[0]=road\n",
        "    z[1][p[0]][p[1]]=1\n",
        "    return z\n",
        "\n",
        "  def __init__(self):\n",
        "    super(RL,self).__init__()\n",
        "\n",
        "    self.l1 = torch.nn.Conv2d(3,8,kernel_size=3,padding=1,bias=False)\n",
        "    self.l11 = torch.nn.Conv2d(11,16,kernel_size=3,padding=1,bias=False)\n",
        "    self.l2 = torch.nn.Conv2d(19,24,kernel_size=3,padding=1,bias=False)\n",
        "    self.l22 = torch.nn.Conv2d(27,32,kernel_size=3,padding=1,bias=False)\n",
        "\n",
        "    self.next = torch.nn.Conv2d(35,15,kernel_size=3,padding=1,bias=False)\n",
        "\n",
        "    self.l3 = torch.nn.Conv2d(35,32,kernel_size=(3,7),bias=False)\n",
        "    self.l4 = torch.nn.Conv2d(35,32,kernel_size=1,bias=False)\n",
        "\n",
        "    self.r = torch.nn.Linear(65,5,bias=False)\n",
        "    self.qa = torch.nn.Linear(65,5,bias=False)\n",
        "\n",
        "  def forward(self,x):\n",
        "    z = torch.nn.functional.leaky_relu(self.l1(x))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l11(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l2(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l22(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "\n",
        "    ss = self.next(z)\n",
        "    ss = torch.clamp(ss, -0.1,1.1) + 0.1*ss\n",
        "\n",
        "    z1 = torch.nn.functional.leaky_relu(self.l3(z))\n",
        "    z1 = z1.view(z.shape[0],32)\n",
        "    z2 = torch.nn.functional.max_pool2d(self.l4(z),kernel_size=(3,7))\n",
        "    z2 = z2.view(z.shape[0],32)\n",
        "    tmp = x[:,2,0,0].view(z.shape[0],1)\n",
        "\n",
        "    z = torch.cat([z1,z2,tmp],dim=1)\n",
        "\n",
        "    qa = self.qa(z)\n",
        "    qa = torch.clamp(qa,min=-1.1,max=2)+0.1*qa\n",
        "    r = self.r(z)\n",
        "    r = torch.clamp(r,min=-1.1,max=0.1)+0.1*r\n",
        "\n",
        "    return qa,r,ss.view(x.shape[0],5,3,3,7)\n",
        "\n",
        "  def toTensorS(self,X):\n",
        "    Z = torch.zeros(len(X),3,3,7)\n",
        "    return torch.stack([self.toTensor(x) for x in X])\n",
        "\n",
        "  def P(self,QA):\n",
        "    return torch.nn.functional.softmax(QA,1)\n",
        "\n",
        "  def Q(self,X):\n",
        "    QA,_,_ = self.forward(X)\n",
        "    return (QA * self.P(QA)).sum(1)\n",
        "\n",
        "  def Qa(self,X,a):\n",
        "    A = torch.zeros(len(X),5).to(device=X.device)\n",
        "    for i in range(len(X)):\n",
        "      A[i][a[i]]=1\n",
        "    QA,R,XX = self.forward(X)\n",
        "    return (QA*A).sum(1),(R*A).sum(1),(XX*A.view(X.shape[0],5,1,1,1)).sum(1)\n",
        "\n",
        "  def policy(self,x):\n",
        "    x = self.toTensor(x).unsqueeze(0)\n",
        "    qa, _, _ = self.forward(x)\n",
        "    p = self.P(qa)\n",
        "    a = torch.multinomial(p, 1).item()\n",
        "    return a"
      ],
      "metadata": {
        "id": "gphvO7eCgYjS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def smoothL1(x):\n",
        "  return torch.min(x*x,x.abs()).mean()\n",
        "\n",
        "def explore(agent, buffer, nbruns):\n",
        "    agent.cpu()\n",
        "    averagetotalreward = 0\n",
        "    for i in range(nbruns):\n",
        "        game = Game()\n",
        "        for j in range(1000):\n",
        "            x = game.getVisibleState()\n",
        "            a = agent.policy(x)\n",
        "            r = game.update(a)\n",
        "            averagetotalreward += r\n",
        "            buffer.append((x, a, r, game.getVisibleState()))\n",
        "\n",
        "            if game.f:\n",
        "              break\n",
        "    return averagetotalreward / nbruns\n",
        "\n",
        "\n",
        "def training(agent, buffer, nbsteps,verbose):\n",
        "    lr = 0.00005\n",
        "    gamma=0.9\n",
        "    if torch.cuda.is_available():\n",
        "      agent.cuda()\n",
        "    optimizer = torch.optim.Adam(agent.parameters(), lr=lr)\n",
        "\n",
        "    buffercopy = []\n",
        "    random.shuffle(buffer)\n",
        "    meanR, meanRL,meanpred=0,0,0\n",
        "    for step in range(nbsteps):\n",
        "        if len(buffer)<64:\n",
        "          break\n",
        "\n",
        "        X, A, R, XX = [],[],torch.zeros(64),[]\n",
        "        for i in range(64):\n",
        "          x, a, r, xx = buffer.pop()\n",
        "          X.append(x)\n",
        "          A.append(a)\n",
        "          R[i]=r\n",
        "          XX.append(xx)\n",
        "          buffercopy.append((x, a, r, xx))\n",
        "\n",
        "        X = agent.toTensorS(X)\n",
        "        XX = agent.toTensorS(XX)\n",
        "        if torch.cuda.is_available():\n",
        "          X,XX,R = X.cuda(),XX.cuda(),R.cuda()\n",
        "\n",
        "        QA,Rpred,XXpred = agent.Qa(X,A)\n",
        "        QXX = agent.Q(XX)\n",
        "\n",
        "        assert QA.shape==QXX.shape\n",
        "        assert QA.shape==R.shape\n",
        "        assert Rpred.shape==R.shape\n",
        "        assert XXpred.shape==XX.shape\n",
        "\n",
        "        rloss = smoothL1(R-Rpred)\n",
        "        XXloss = smoothL1(XX-XXpred)\n",
        "        RLloss = smoothL1(gamma*QXX+R-QA)\n",
        "\n",
        "        meanR+=float(rloss)\n",
        "        meanRL+=float(RLloss)\n",
        "        meanpred+=float(XXloss)\n",
        "        if step % 20 == 19 and verbose:\n",
        "            print(\"\\t\", step, meanR/20,meanRL/20,meanpred/20)\n",
        "            meanR,meanRL,meanpred=0,0,0\n",
        "\n",
        "        loss = RLloss+rloss+XXloss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(agent.parameters(), 10)\n",
        "        optimizer.step()\n",
        "\n",
        "    return buffercopy+buffer"
      ],
      "metadata": {
        "id": "SJM-H564oHzF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = []\n",
        "agent = RL()\n",
        "score = explore(agent, buffer, 100) #warmup\n",
        "for i in range(400):\n",
        "  score = explore(agent, buffer, 10)\n",
        "  if i%12==0:\n",
        "      print(i, \"score\",score, len(buffer))\n",
        "  buffer = training(agent, buffer, 100, i%12==0)\n",
        "  if len(buffer)>100000:\n",
        "    random.shuffle(buffer)\n",
        "    buffer = buffer[0:100000]\n",
        "\n",
        "print(\"final score\", explore(agent, buffer, 1000))"
      ],
      "metadata": {
        "id": "jnvcJnpCthNN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}