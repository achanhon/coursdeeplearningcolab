{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNbclGdPUuuC3D7OD46foX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d6vD1dKKgOH0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Game:\n",
        "  def __init__(self,other=None):\n",
        "    self.A = [(0,1),(-1,0),(1,0),(0,0),(0,2)]\n",
        "    if other is None:\n",
        "      self.t = 0\n",
        "      self.f=False\n",
        "      self.p = (1,0)\n",
        "      self.road = (torch.rand(3,100)<0.05).half()\n",
        "      self.road[:,0:2]=0\n",
        "    else:\n",
        "      self.p,self.t,self.f,self.road = other\n",
        "\n",
        "  def copy(self):\n",
        "    return Game((self.p,self.t,self.f,self.road))\n",
        "\n",
        "  def getVisibleState(self):\n",
        "    return (self.p[0],self.p[1]-self.t), self.road[:,self.t:self.t+7], self.f\n",
        "\n",
        "  def getVisibleStateString(self):\n",
        "    p,road = self.getVisibleState()\n",
        "    string_parts = []\n",
        "    for r in range(3):\n",
        "      for c in range(7):\n",
        "        if road[r][c]==1:\n",
        "          string_parts.append(\"o\")\n",
        "        else:\n",
        "          string_parts.append(\" \")\n",
        "        if r==p[0] and c==p[1]:\n",
        "          string_parts[-1]=\"x\"\n",
        "      string_parts.append(\"\\n\")\n",
        "    return \"----------\\n\"+\"\".join(string_parts)+\"----------\"\n",
        "\n",
        "  def update(self,a):\n",
        "    assert not self.f, print(\"update a final state\")\n",
        "    dr,dc = self.A[a]\n",
        "    p = self.p\n",
        "\n",
        "    # remove forbidden action\n",
        "    if p[1]==self.t and dc<1:\n",
        "      dr,dc = 0,1\n",
        "    if p[0]+dr<0:\n",
        "      dr,dc = 0,1\n",
        "    if p[0]+dr>2:\n",
        "      dr,dc=0,1\n",
        "    if p[1]+dc>self.t+5:\n",
        "      dr,dc = 0,1\n",
        "\n",
        "    if self.road[p[0]+dr][p[1]+dc]==1:\n",
        "      self.f = True\n",
        "      return -10\n",
        "    if dc==2 and self.road[p[0]][p[1]+1]==1:\n",
        "      self.f = True\n",
        "      return -10\n",
        "\n",
        "    self.p = (p[0]+dr,p[1]+dc)\n",
        "    self.t = self.t+1\n",
        "    if self.t==90:\n",
        "      self.f = True\n",
        "    return 0.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RL(torch.nn.Module):\n",
        "  def toTensor(self,x):\n",
        "    z = torch.zeros(3,3,7)\n",
        "    p,road,f = x\n",
        "    if f:\n",
        "      return z\n",
        "    z[2,:,:]=1\n",
        "    z[0]=road\n",
        "    z[1][p[0]][p[1]]=1\n",
        "    return z\n",
        "\n",
        "  def __init__(self):\n",
        "    super(RL,self).__init__()\n",
        "\n",
        "    self.l1 = torch.nn.Conv2d(3,8,kernel_size=3,padding=1,bias=False)\n",
        "    self.l11 = torch.nn.Conv2d(11,16,kernel_size=3,padding=1,bias=False)\n",
        "    self.l2 = torch.nn.Conv2d(19,24,kernel_size=3,padding=1,bias=False)\n",
        "    self.l22 = torch.nn.Conv2d(27,32,kernel_size=3,padding=1,bias=False)\n",
        "\n",
        "    self.next = torch.nn.Conv2d(35,15,kernel_size=3,padding=1,bias=False)\n",
        "\n",
        "    self.l3 = torch.nn.Conv2d(35,32,kernel_size=(3,7),bias=False)\n",
        "    self.l4 = torch.nn.Conv2d(35,32,kernel_size=1,bias=False)\n",
        "\n",
        "    self.r = torch.nn.Linear(65,5,bias=False)\n",
        "    self.qa = torch.nn.Linear(65,5,bias=False)\n",
        "\n",
        "  def forward(self,x):\n",
        "    z = torch.nn.functional.leaky_relu(self.l1(x))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l11(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l2(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l22(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "\n",
        "    ss = self.next(z)\n",
        "    ss = torch.clamp(ss, -0.1,1.1) + 0.1*ss*((ss>1.1).float()+(ss<-0.1).float())\n",
        "\n",
        "    z1 = torch.nn.functional.leaky_relu(self.l3(z))\n",
        "    z1 = z1.view(z.shape[0],32)\n",
        "    z2 = torch.nn.functional.max_pool2d(self.l4(z),kernel_size=(3,7))\n",
        "    z2 = z2.view(z.shape[0],32)\n",
        "    tmp = x[:,2,0,0].view(z.shape[0],1)\n",
        "\n",
        "    z = torch.cat([z1,z2,tmp],dim=1)\n",
        "\n",
        "    qa = self.qa(z)\n",
        "    qa = torch.clamp(qa,min=-11,max=20)+0.1*qa*((qa<-11).float()+(qa>20).float())\n",
        "    r = self.r(z)\n",
        "    r = torch.clamp(r,min=-11,max=2)+0.1*r*((r<-11).float()+(r>2).float())\n",
        "\n",
        "    return qa,r,ss.view(x.shape[0],5,3,3,7)\n",
        "\n",
        "  def toTensorS(self,X):\n",
        "    Z = torch.zeros(len(X),3,3,7)\n",
        "    return torch.stack([self.toTensor(x) for x in X])\n",
        "\n",
        "  def P(self,QA):\n",
        "    return torch.nn.functional.softmax(QA,1)\n",
        "\n",
        "  def Q(self,X):\n",
        "    QA,_,_ = self.forward(X)\n",
        "    return (QA * self.P(QA)).sum(1)\n",
        "\n",
        "  def Qa(self,X,a):\n",
        "    A = torch.zeros(len(X),5).to(device=X.device)\n",
        "    for i in range(len(X)):\n",
        "      A[i][a[i]]=1\n",
        "    QA,R,XX = self.forward(X)\n",
        "    return (QA*A).sum(1),(R*A).sum(1),(XX*A.view(X.shape[0],5,1,1,1)).sum(1)\n",
        "\n",
        "  def policy(self,x):\n",
        "    x = self.toTensor(x).unsqueeze(0)\n",
        "    qa, _, _ = self.forward(x)\n",
        "    p = self.P(qa)\n",
        "    a = torch.multinomial(p, 1).item()\n",
        "    return a"
      ],
      "metadata": {
        "id": "gphvO7eCgYjS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def smoothL1(x):\n",
        "  return torch.min(x*x,x.abs()).mean()\n",
        "\n",
        "def explore(agent, buffer, nbruns):\n",
        "    agent.cpu()\n",
        "    averagetotalreward = 0\n",
        "    for i in range(nbruns):\n",
        "        game = Game()\n",
        "        for j in range(1000):\n",
        "            x = game.getVisibleState()\n",
        "            a = agent.policy(x)\n",
        "            r = game.update(a)\n",
        "            averagetotalreward += r\n",
        "            buffer.append((x, a, r, game.getVisibleState()))\n",
        "\n",
        "            if game.f:\n",
        "              break\n",
        "    return averagetotalreward / nbruns\n",
        "\n",
        "\n",
        "def training(agent, buffer, nbsteps,verbose):\n",
        "    lr = 0.00001\n",
        "    gamma=0.9\n",
        "    if torch.cuda.is_available():\n",
        "      agent.cuda()\n",
        "    optimizer = torch.optim.Adam(agent.parameters(), lr=lr)\n",
        "\n",
        "    buffercopy = []\n",
        "    random.shuffle(buffer)\n",
        "    meanR, meanRL,meanpred=0,0,0\n",
        "    for step in range(nbsteps):\n",
        "        if len(buffer)<64:\n",
        "          break\n",
        "\n",
        "        X, A, R, XX = [],[],torch.zeros(64),[]\n",
        "        for i in range(64):\n",
        "          x, a, r, xx = buffer.pop()\n",
        "          X.append(x)\n",
        "          A.append(a)\n",
        "          R[i]=r\n",
        "          XX.append(xx)\n",
        "          buffercopy.append((x, a, r, xx))\n",
        "\n",
        "        X = agent.toTensorS(X)\n",
        "        XX = agent.toTensorS(XX)\n",
        "        if torch.cuda.is_available():\n",
        "          X,XX,R = X.cuda(),XX.cuda(),R.cuda()\n",
        "\n",
        "        QA,Rpred,XXpred = agent.Qa(X,A)\n",
        "        QXX = agent.Q(XX)\n",
        "\n",
        "        assert QA.shape==QXX.shape\n",
        "        assert QA.shape==R.shape\n",
        "        assert Rpred.shape==R.shape\n",
        "        assert XXpred.shape==XX.shape\n",
        "\n",
        "        rloss = smoothL1(R-Rpred)\n",
        "        XXloss = smoothL1(XX-XXpred) #WTF\n",
        "        RLloss = smoothL1(gamma*QXX+R-QA)\n",
        "\n",
        "        meanR+=float(rloss)\n",
        "        meanRL+=float(RLloss)\n",
        "        meanpred+=float(XXloss)\n",
        "        if step % 20 == 19 and verbose:\n",
        "            print(\"\\t\", step, meanR/20,meanRL/20,meanpred/20)\n",
        "            meanR,meanRL,meanpred=0,0,0\n",
        "\n",
        "        loss = RLloss+0.1*rloss+0.1*XXloss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(agent.parameters(), 10)\n",
        "        optimizer.step()\n",
        "\n",
        "    return buffercopy+buffer"
      ],
      "metadata": {
        "id": "SJM-H564oHzF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = []\n",
        "agent = RL()\n",
        "score = explore(agent, buffer, 100) #warmup\n",
        "for i in range(200):\n",
        "  score = explore(agent, buffer, 10)\n",
        "  if i%6==0:\n",
        "      print(i, \"score\",score, len(buffer))\n",
        "  buffer = training(agent, buffer, 100, i%6==0)\n",
        "  if len(buffer)>100000:\n",
        "    random.shuffle(buffer)\n",
        "    buffer = buffer[0:100000]\n",
        "\n",
        "print(\"final score\", explore(agent, buffer, 1000))"
      ],
      "metadata": {
        "id": "jnvcJnpCthNN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "3c8d6648-c6c8-49d9-8f48-32441585fd95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 score -7.228000000000035 1879\n",
            "\t 19 0.6442693173885345 0.6303875915706157 0.06032986082136631\n",
            "6 score -8.464000000000008 2974\n",
            "\t 19 0.665178612805903 0.6487445747014136 0.061024305410683155\n",
            "\t 39 0.5383306369185448 0.5230336777865887 0.05602678544819355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7f8278368d30>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-04344aeb9604>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-996d0568f934>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(agent, buffer, nbsteps, verbose)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRLloss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrloss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mXXloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}