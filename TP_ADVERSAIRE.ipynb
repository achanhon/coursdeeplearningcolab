{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/TP_ADVERSAIRE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZhlLxX-l_5m"
      },
      "source": [
        "#TP deep learning sous attaque adversaire (2024)\n",
        "####Adrien Chan-Hon-Tong\n",
        "####TP réalisé à partir de résultats de Pol Labarbarie\n",
        "\n",
        "\n",
        "L'objet de ce TP est de démontrer\n",
        "- la faciliter de produire des attaques adversaires \"white box\" sur des réseaux naifs quelles soient invisibles ou par patch\n",
        "- mais que cela est beaucoup plus dur sur un réseau robustifier (cas invisible)\n",
        "- ou encore qu'il est beaucoup plus difficile de produire des attaques \"transferable\"\n",
        "\n",
        "## generalité\n",
        "Commençons par télécharger 10 images d'imagenet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6FDb1CEFqXa",
        "outputId": "c7111df3-972a-493d-af19-b76ef6d9d147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'build': Is a directory\n",
            "rm: cannot remove 'sample_data': Is a directory\n",
            "--2024-10-05 09:40:31--  https://httpmail.onera.fr/21/500df56b6a7a034ecc2f3e0345f1ce9cYqsE3G/data.zip\n",
            "Resolving httpmail.onera.fr (httpmail.onera.fr)... 144.204.16.9\n",
            "Connecting to httpmail.onera.fr (httpmail.onera.fr)|144.204.16.9|:443... failed: No route to host.\n",
            "unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\n",
            "build  sample_data\n"
          ]
        }
      ],
      "source": [
        "!rm -f *\n",
        "!wget https://httpmail.onera.fr/21/500df56b6a7a034ecc2f3e0345f1ce9cYqsE3G/data.zip\n",
        "!unzip data.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arTqlxWjK1UQ"
      },
      "source": [
        "Affichons les : les 5 premières sont des \"avions\" et les 5 suivantes des \"requins\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "x7OtnMFzl_HU",
        "outputId": "ae77246f-bccf-4ba6-e3a6-2ec2b91155e5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "[Errno 2] No such file or directory: '0.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-74a28adc7901>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-74a28adc7901>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(path, mode, apply_exif_orientation)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_exif_orientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_exif_orientation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [Errno 2] No such file or directory: '0.png'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [torchvision.io.read_image(str(i)+\".png\") for i in range(10)]\n",
        "x = torch.stack(x,dim=0).float()/255\n",
        "\n",
        "visu = torchvision.utils.make_grid(x, nrow=5)\n",
        "plt.imshow(visu.permute(1, 2, 0).numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9I5vYlpLRAF"
      },
      "outputs": [],
      "source": [
        "SHARK, PLANE = [2, 3, 4], [403, 404, 405]\n",
        "normalize = torchvision.transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "resnet = torchvision.models.resnet101(\n",
        "    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",
        ").eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = resnet(normalize(x))\n",
        "    _,z = z.max(1)\n",
        "    print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8Ti-1roOsJ7"
      },
      "source": [
        "On voit que le réseau classe correctement ces images.\n",
        "\n",
        "## Attaque standard \"white box\"\n",
        "\n",
        "On va maintenant rajouter à ces images un petit bruit \"invisible\" pour l'oeil mais perturbant pour le réseau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idDfEQKFFejn"
      },
      "outputs": [],
      "source": [
        "y = torch.Tensor([403, 405, 404, 405, 404,   4,   3,   3,   3,   2]).long()\n",
        "cefunction = torch.nn.CrossEntropyLoss()\n",
        "attaque = torch.nn.Parameter(torch.zeros(x.shape))\n",
        "optimizer = torch.optim.SGD([attaque],lr=0.005)\n",
        "for i in range(10):\n",
        "  z = resnet(normalize(x+attaque))\n",
        "  ce = cefunction(z,y)\n",
        "  print(i,float(ce))\n",
        "  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n",
        "  optimizer.zero_grad()\n",
        "  ce.backward()\n",
        "  attaque.grad = attaque.grad.sign()\n",
        "  optimizer.step()\n",
        "  with torch.no_grad():\n",
        "      # l'attaque doit être invisible\n",
        "      attaque = torch.clamp(attaque, -10./255,+10./255)\n",
        "\n",
        "      # attaque+x doit être entre 0 et 1\n",
        "      lowbound = -x\n",
        "      uppbound = 1-x\n",
        "      attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n",
        "\n",
        "  attaque = torch.nn.Parameter(attaque.clone())\n",
        "  optimizer = torch.optim.SGD([attaque],lr=0.005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmMDfE1AR6hx"
      },
      "source": [
        "80% des images \"x+attaque\" sont désormais mal classées ! (et le label de toutes à changer)\n",
        "Pourtant, l'attaque ne se voit pas :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W236tA8DSGHu"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    z = resnet(normalize(x))\n",
        "    _,z = z.max(1)\n",
        "    print(z)\n",
        "    z = resnet(normalize(x+attaque))\n",
        "    _,z = z.max(1)\n",
        "    print(z)\n",
        "\n",
        "visu = torch.cat([x,x+attaque],dim=0)\n",
        "visu = torchvision.utils.make_grid(visu, nrow=5)\n",
        "plt.imshow(visu.permute(1, 2, 0).numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment est ce que c'est possible ? Les réseaux ne sont pas du tout lipschitziens..."
      ],
      "metadata": {
        "id": "kR3NAbhIID13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    resnet = torchvision.models.resnet101(\n",
        "        weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",
        "    ).eval()\n",
        "    resnet.fc = torch.nn.Identity()\n",
        "    z = resnet(x)\n",
        "    print(((z[0]-z[5])**2).sum())\n",
        "    z_ = resnet(x+attaque)\n",
        "    print(((z[0]-z_[0])**2).sum())"
      ],
      "metadata": {
        "id": "zVA7QMbyJgOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On voit que la représentation de l'image 0 devient presque aussi lointaine à cause de l'attaque que la distance avec l'image 5 !\n",
        "Alors que nous ne voyons même pas la différence !\n",
        "\n",
        "____________________________________________________________________________\n",
        "=> retour aux slides (on revient ici après).\n",
        "____________________________________________________________________________\n",
        "\n",
        "# Attaque standard par patch \"white box\"\n",
        "Maintenant on va regarder la création d'un patch adversarial : pour rappel, le problème des bruits invisibles c'est l'impossibilité de les faire dans le monde physique et l'existance de défense -> deux choses que les patches peuvent bypasser.\n",
        "\n",
        "On va mettre un patch 36x36 en haut à gauche (remarquons que si le patch est juste noir, ça change rien)."
      ],
      "metadata": {
        "id": "k59OChLKKXnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.zeros(1,3,224,224)\n",
        "mask[:,:,0:36,0:36] = 1\n",
        "\n",
        "resnet = torchvision.models.resnet101(\n",
        "    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",
        ").eval()\n",
        "with torch.no_grad():\n",
        "    z = resnet(normalize(x))\n",
        "    _,z = z.max(1)\n",
        "    print(z)\n",
        "    z = resnet(normalize(x*(1-mask)))\n",
        "    _,z = z.max(1)\n",
        "    print(z)\n",
        "\n",
        "visu = torch.cat([x,x*(1-mask)],dim=0)\n",
        "visu = torchvision.utils.make_grid(visu, nrow=5)\n",
        "plt.imshow(visu.permute(1, 2, 0).numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0mdKRmHdS8Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mais s'il est optimisé ?"
      ],
      "metadata": {
        "id": "4sEsZnlaTjJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.Tensor([403, 405, 404, 405, 404,   4,   3,   3,   3,   2]).long()\n",
        "cefunction = torch.nn.CrossEntropyLoss()\n",
        "attaque = torch.nn.Parameter(torch.rand(1,3,224,224))\n",
        "optimizer = torch.optim.SGD([attaque],lr=0.1)\n",
        "for i in range(40):\n",
        "  z = resnet(normalize(x*(1-mask)+mask*attaque))\n",
        "  ce = cefunction(z,y)\n",
        "  print(i,float(ce))\n",
        "  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n",
        "  optimizer.zero_grad()\n",
        "  ce.backward()\n",
        "  attaque.grad = attaque.grad.sign()\n",
        "  optimizer.step()\n",
        "  with torch.no_grad():\n",
        "      # l'attaque doit être dans le domaine image\n",
        "      attaque = torch.clamp(attaque, 0,1)\n",
        "\n",
        "  attaque = torch.nn.Parameter(attaque.clone())\n",
        "  if i<20:\n",
        "      optimizer = torch.optim.SGD([attaque],lr=0.1)\n",
        "  else:\n",
        "      optimizer = torch.optim.SGD([attaque],lr=0.05)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = resnet(normalize(x))\n",
        "    _,z = z.max(1)\n",
        "    print(z)\n",
        "    z = resnet(normalize(x*(1-mask) + attaque*mask))\n",
        "    _,z = z.max(1)\n",
        "    print(z)\n",
        "\n",
        "visu = torch.cat([x,x*(1-mask)+attaque*mask],dim=0)\n",
        "visu = torchvision.utils.make_grid(visu, nrow=5)\n",
        "plt.imshow(visu.permute(1, 2, 0).numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "az8_ho5lLWbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Des images ont vu leur label changé (c'est ici pas 100% mais c'est le MÊME patch pour toutes les images - et il n'est pas vraiment optimisé suffisamment longtemps).\n",
        "\n",
        "## Limites\n",
        "\n",
        "Ici on montre la facilité de faire une attaque **numérique** contre un réseau **naif** et **connu**.\n",
        "Heureusement, la situation est très différente contre un réseau *défendu* ou *inconnu* ou quand l'attaque doit être *physiquement réalisable*.\n",
        "\n",
        "### Réseaux défendus\n",
        "\n",
        "On trouve très peu de réseaux défendus sur internet pour Imagenet (on trouve surtout des réseaux CIFAR et les rares qu'on peut trouver pour Imagenet comme dans le github https://github.com/MadryLab/robustness sont des réseaux custom).\n",
        "Aussi, nous allons abandonnés nos avions/requins et faire des petites expériences sur CIFAR10.\n",
        "\n",
        "Commençons par apprendre un réseau sur CIFAR:"
      ],
      "metadata": {
        "id": "JeoPFyyhldXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "normalize = torchvision.transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),normalize])\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1kLcM0QXF6n",
        "outputId": "db4429df-8f33-4bd0-9a98-a34136f331c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to build/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 54672409.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting build/cifar-10-python.tar.gz to build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torchvision.models.resnet18(\n",
        "    weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
        ").eval()\n",
        "resnet.fc = torch.nn.Linear(512,10)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
        ")\n",
        "cefunction = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.0001)\n",
        "meanloss = torch.zeros(50)\n",
        "for i,(x,y) in enumerate(trainloader):\n",
        "    z=resnet(x)\n",
        "    loss = cefunction(z,y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        meanloss[i%50]=loss.clone()\n",
        "        if i%50==49:\n",
        "          print(float(meanloss.mean()))\n",
        "    if i==1000:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT3aTtf-XI1y",
        "outputId": "f1ec6f8d-9124-471f-84f3-0bb1d5546b68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5134620666503906\n",
            "1.0475107431411743\n",
            "0.885348916053772\n",
            "0.8793100714683533\n",
            "0.7926767468452454\n",
            "0.7795549035072327\n",
            "0.7765563130378723\n",
            "0.7171671986579895\n",
            "0.6997859477996826\n",
            "0.7229669690132141\n",
            "0.6560990214347839\n",
            "0.6875853538513184\n",
            "0.6767550110816956\n",
            "0.682990312576294\n",
            "0.6401225924491882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vérifions que la perfo est pas trop mauvaise même si là on a appris vraiment très très très peu :"
      ],
      "metadata": {
        "id": "HfSHsT0hfx2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=500, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x,y in testloader:\n",
        "        z = resnet(x)\n",
        "        _,z = z.max(1)\n",
        "        good = (z==y).float().sum()\n",
        "        print(float(good/5))\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-QLjDDLV1u_",
        "outputId": "3071bee5-43d2-4d09-bec0-6a2941c9c335"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "79.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c'est pas \"terrible\" mais ça ira pour la preuve de concept...\n",
        "\n",
        "attaquons 10 images bien classée !"
      ],
      "metadata": {
        "id": "tUVr78-ChjHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "I = [i for i in range(500) if y[i]==z[i]]\n",
        "I = I[0:10]\n",
        "y,x=y[I],x[I]\n",
        "#ces 10 là sont bien classées !\n",
        "\n",
        "cefunction = torch.nn.CrossEntropyLoss()\n",
        "attaque = torch.nn.Parameter(torch.zeros(x.shape))\n",
        "optimizer = torch.optim.SGD([attaque],lr=0.005)\n",
        "for i in range(25):\n",
        "  z = resnet(x+attaque)\n",
        "  ce = cefunction(z,y)\n",
        "  print(i,float(ce))\n",
        "  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n",
        "  optimizer.zero_grad()\n",
        "  ce.backward()\n",
        "  attaque.grad = attaque.grad.sign()\n",
        "  optimizer.step()\n",
        "  with torch.no_grad():\n",
        "    # l'attaque doit être invisible\n",
        "    attaque = torch.clamp(attaque, -10./255,+10./255)\n",
        "\n",
        "    # attaque+x doit être entre 0 et 1\n",
        "    lowbound = -x\n",
        "    uppbound = 1-x\n",
        "    attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n",
        "\n",
        "  attaque = torch.nn.Parameter(attaque.clone())\n",
        "  optimizer = torch.optim.SGD([attaque],lr=0.005)\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = resnet(x)\n",
        "  _,z = z.max(1)\n",
        "  print(z)\n",
        "  z = resnet(x+attaque)\n",
        "  _,z = z.max(1)\n",
        "  print(z)\n",
        "\n",
        "visu = torch.cat([x,x+attaque],dim=0)\n",
        "visu = torchvision.utils.make_grid(visu, nrow=5)\n",
        "plt.imshow(visu.permute(1, 2, 0).numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "collapsed": true,
        "id": "xOFXzOiNhuwO",
        "outputId": "c5ed69fd-8e46-4e9d-9dbf-39c1a4d4e7cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.11965018510818481\n",
            "1 2.4779820442199707\n",
            "2 2.6715633869171143\n",
            "3 2.875704288482666\n",
            "4 3.084207773208618\n",
            "5 3.2871639728546143\n",
            "6 3.4851067066192627\n",
            "7 3.678542375564575\n",
            "8 3.8522675037384033\n",
            "9 3.9444000720977783\n",
            "10 4.02327823638916\n",
            "11 4.048834323883057\n",
            "12 4.071587562561035\n",
            "13 4.088166236877441\n",
            "14 4.101597785949707\n",
            "15 4.111011505126953\n",
            "16 4.1196818351745605\n",
            "17 4.126502513885498\n",
            "18 4.132266044616699\n",
            "19 4.136849880218506\n",
            "20 4.140960693359375\n",
            "21 4.144164085388184\n",
            "22 4.148486137390137\n",
            "23 4.14995002746582\n",
            "24 4.152886390686035\n",
            "tensor([1, 8, 6, 4, 8, 0, 3, 7, 2, 1])\n",
            "tensor([2, 0, 2, 2, 0, 0, 2, 0, 2, 0])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6da1c20b17b5>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mvisu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mattaque\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mvisu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bon même si on est pas à 10/10, on voit que le modèle (pourtant non convergé) est quand même très sensible...\n",
        "\n",
        "maintenant regardons si on apprend un modèle **robuste**."
      ],
      "metadata": {
        "id": "EnTmtd70k34l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet,\"resnet.pth\")\n",
        "resnetrobuste = torch.load(\"resnet.pth\") #force unrelated copy\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
        ")\n",
        "cefunction = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(resnetrobuste.parameters(), lr=0.0001)\n",
        "meanloss = torch.zeros(50)\n",
        "for i,(x,y) in enumerate(trainloader):\n",
        "    #attack x, then update the weight to deal with the fact that z has been attacked\n",
        "    attaque = torch.nn.Parameter(torch.zeros(x.shape))\n",
        "    attackoptimizer = torch.optim.SGD([attaque],lr=0.001)\n",
        "    for _ in range(10):\n",
        "      z = resnet(x+attaque)\n",
        "      ce = cefunction(z,y)\n",
        "      ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n",
        "      optimizer.zero_grad()\n",
        "      ce.backward()\n",
        "      attaque.grad = attaque.grad.sign()\n",
        "      optimizer.step()\n",
        "\n",
        "    #now attaque is frozen\n",
        "    with torch.no_grad():\n",
        "        attaque = torch.Tensor(attaque.clone())\n",
        "\n",
        "    z = resnetrobuste(x+attaque)\n",
        "    loss = cefunction(z,y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        meanloss[i%50]=loss.clone()\n",
        "        if i%50==49:\n",
        "          print(float(meanloss.mean()))\n",
        "\n",
        "        if i%5==4:\n",
        "          torch.save(resnetrobuste,\"tmp.pth\")\n",
        "          resnet = torch.load(\"tmp.pth\") #update the network from which attack is crafted\n",
        "    if i==400:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m0QzqYwmoAy",
        "outputId": "886c4abf-5211-41ae-9a5c-e708412bedb0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-cad2277aec7e>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnetrobuste = torch.load(\"resnet.pth\") #force unrelated copy\n",
            "<ipython-input-5-cad2277aec7e>:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet = torch.load(\"tmp.pth\") #update the network from which attack is crafted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5893574357032776\n",
            "0.5478807091712952\n",
            "0.541315495967865\n",
            "0.5166321396827698\n",
            "0.5541200041770935\n",
            "0.5064505934715271\n",
            "0.5226083993911743\n",
            "0.5241930484771729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "la performance sur les images \"normales\" devraient avoir baissée"
      ],
      "metadata": {
        "id": "jMTb4MDy3AhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for x,y in testloader:\n",
        "        z = resnetrobuste(x)\n",
        "        _,z = z.max(1)\n",
        "        good = (z==y).float().sum()\n",
        "        print(float(good/5))\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svKd8WeP2_sb",
        "outputId": "31fc809e-23b0-4158-f52c-351332ace629"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70.80000305175781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mais la performance devrait rester similaire sur des images attaquées"
      ],
      "metadata": {
        "id": "TnEhBFWY3LPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "I = [i for i in range(500) if y[i]==z[i]]\n",
        "I = I[0:10]\n",
        "y,x=y[I],x[I]\n",
        "#ces 10 là sont bien classées !\n",
        "\n",
        "cefunction = torch.nn.CrossEntropyLoss()\n",
        "attaque = torch.nn.Parameter(torch.zeros(x.shape))\n",
        "optimizer = torch.optim.SGD([attaque],lr=0.005)\n",
        "for i in range(25):\n",
        "  z = resnetrobuste(x+attaque)\n",
        "  ce = cefunction(z,y)\n",
        "  print(i,float(ce))\n",
        "  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n",
        "  optimizer.zero_grad()\n",
        "  ce.backward()\n",
        "  attaque.grad = attaque.grad.sign()\n",
        "  optimizer.step()\n",
        "  with torch.no_grad():\n",
        "    # l'attaque doit être invisible\n",
        "    attaque = torch.clamp(attaque, -10./255,+10./255)\n",
        "\n",
        "    # attaque+x doit être entre 0 et 1\n",
        "    lowbound = -x\n",
        "    uppbound = 1-x\n",
        "    attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n",
        "\n",
        "  attaque = torch.nn.Parameter(attaque.clone())\n",
        "  optimizer = torch.optim.SGD([attaque],lr=0.005)\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = resnetrobuste(x)\n",
        "  _,z = z.max(1)\n",
        "  print(z)\n",
        "  z = resnetrobuste(x+attaque)\n",
        "  _,z = z.max(1)\n",
        "  print(z)\n",
        "\n",
        "visu = torch.cat([x,x+attaque],dim=0)\n",
        "visu = torchvision.utils.make_grid(visu, nrow=5)\n",
        "plt.imshow(visu.permute(1, 2, 0).numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "7XXYQ8jm3R1e",
        "outputId": "ff252e0b-0d08-4e6d-c6df-54d0848ff5b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.1014028787612915\n",
            "1 1.3002005815505981\n",
            "2 1.4649325609207153\n",
            "3 1.6515552997589111\n",
            "4 1.8567759990692139\n",
            "5 2.0755035877227783\n",
            "6 2.3042683601379395\n",
            "7 2.5269718170166016\n",
            "8 2.735957622528076\n",
            "9 2.8491945266723633\n",
            "10 2.9443023204803467\n",
            "11 2.9743831157684326\n",
            "12 3.004638195037842\n",
            "13 3.024829387664795\n",
            "14 3.0413613319396973\n",
            "15 3.055093288421631\n",
            "16 3.0629239082336426\n",
            "17 3.075079917907715\n",
            "18 3.08308744430542\n",
            "19 3.0888679027557373\n",
            "20 3.0954604148864746\n",
            "21 3.100970983505249\n",
            "22 3.105414390563965\n",
            "23 3.1106009483337402\n",
            "24 3.112619400024414\n",
            "tensor([3, 6, 8, 3, 9, 1, 6, 6, 9, 1])\n",
            "tensor([3, 6, 4, 3, 0, 6, 0, 6, 3, 3])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-12d9b3a8c00a>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mvisu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mattaque\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mvisu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnUps7iqLPg+IU7/IsngvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}