{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/bow_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTUF2gpAcOr5"
      },
      "source": [
        "# TP Sac de mot\n",
        "\n",
        "L'objectif de ce tp est de coder une approche sac de mots : c'est ce qu'on faisait de mieux **avant** le deep learning.\n",
        "\n",
        "Alternativement, vous pouvez aussi regarder les questions en fin de TP qui porte sur des méthodes d'auto encoding par deep learning (mais on est en limite de ce qu'on peut faire avec collab).\n",
        "\n",
        "\n",
        "On va réutiliser MNIST que vous connaissez désormais.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGNwRuVjdE5W"
      },
      "source": [
        "## Création d'un dictionnaire\n",
        "\n",
        "On va extraire un ensemble dense de patch dans des images MNIST et appliquer K moyenne dessus, cela nous donnera un dictionnaire de patches !\n",
        "\n",
        "D'abord récupérons MNIST (avec torchvision -- juste par faciliter mais ce n'est pas pertinent)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouvhsCnwdPgm"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "transform_mnist = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((32,32)),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "mnisttrain = torchvision.datasets.MNIST(\"./mnist\",train=True, transform=transform_mnist, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(mnisttrain, batch_size=64, shuffle=True, num_workers=2)\n",
        "mnisttest = torchvision.datasets.MNIST(\"./mnist\",train=False, transform=transform_mnist, download=True)\n",
        "testloader = torch.utils.data.DataLoader(mnisttest, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "sample = next(iter(trainloader))[0]\n",
        "show(torchvision.utils.make_grid(sample))\n",
        "print(sample.shape)  ## 64 c'est le batch\n",
        "                        ## 1 c'est du gris -- sinon ce serait 3 pour du RGB\n",
        "                        ## 32x32 c'est pour la taille de l'image (petite ici)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gNOHjffefzg"
      },
      "source": [
        "**Q1** (moyen) : écrire une fonction qui extrait des patch 8x8 dans une image, les transforme en vecteur (flatten) et les mets dans une liste donnée en argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBPJ5pdmdghW"
      },
      "source": [
        "def extraitpatch2D(allpatch,inputs):\n",
        "  print(\"TODO\")\n",
        "\n",
        "def extraitpatchinbatch(allpatch,inputs):\n",
        "  for i in range(inputs.shape[0]):\n",
        "      extraitpatch2D(allpatch,inputs[i][0].cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iauL3XSqfISU"
      },
      "source": [
        "**ATTENTION :** en fait c'est vraiment consommateur de ressource d'extraire autant de patches...\n",
        "\n",
        "On vous fourniera une version qui tire de façon efficace des patchs à extraire au hasard de sorte que chaque position soit équiprobable.\n",
        "\n",
        "**Q2 (facile)** : utiliser la fonction show64patches pour visualiser 64 patchs tirés au hasard et/ou les patchs extraits d'une image unique. Chacun apporte une information \"faible\" mais dans leur ensemble, on espère qu'ils encodent l'image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6CxcGFzCord"
      },
      "source": [
        "import random\n",
        "\n",
        "def show64patch(patches):\n",
        "  patches = [torch.Tensor(patches[i]) for i in range(64)]\n",
        "  patches = [patch.view(8,8) for patch in patches]\n",
        "  patches = [patch.unsqueeze(0) for patch in patches]\n",
        "  patches = torch.stack(patches)\n",
        "  show(torchvision.utils.make_grid(patches))\n",
        "\n",
        "tmp = []\n",
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0VqQCfVEhYr"
      },
      "source": [
        "**Q3 (facile)** Parcourer le dataset de train pour extraire \"l'ensemble\" des patchs de l'ensemble des images (normalement on utilise train **ET** test mais bon)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5GqZNlohsM3"
      },
      "source": [
        "allpatch = []\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhlChYqxFjl8"
      },
      "source": [
        "**Q4 (moyen)** : Appliquer sklearn.cluster.KMeans pour créer un dictionnaire de 512 clusters\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        "\n",
        "\n",
        "c'est normal si ça prend 10 mins !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFrKO733GDrR"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "print(len(allpatch)) ## on a un gros problème Kmeans !! \n",
        "                     ## dimension des vecteurs 64, \n",
        "                     ## K = 512\n",
        "                     ## N = 600000\n",
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtunFS0S4qYQ"
      },
      "source": [
        "**Q5 (facile)** : avez vous utiliser la classe des images jusqu'à maintenant ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR3KCn3g5i6W"
      },
      "source": [
        "Non pour l'instant on utilise que de la données !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ipypqT-iRb"
      },
      "source": [
        "del allpatch  ### libérer de la ram\n",
        "print(kmeans.cluster_centers_.shape) ### vérification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plvLXR2-GH5B"
      },
      "source": [
        "## Encodage\n",
        "\n",
        "L'objectif maintenant est d'utiliser le dictionnaire pour créer une fonction qui prend une image en entrée et qui produit un histogramme H avec h_i qui correspond au nombre de fois qu'on a vu un patch qui se rattache au groupe \"i\" du dictionnaire !\n",
        "\n",
        "cette fois on extraira tous les patchs -- vu que de toute façon on va juste en conserver leur index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6GqksktIDKe"
      },
      "source": [
        "def extractallpatch(allpatch,image):\n",
        "  for row in range(image.shape[0]-8):\n",
        "    for col in range(image.shape[1]-8):\n",
        "        allpatch.append(image[row:row+8,col:col+8].copy().flatten())\n",
        "\n",
        "def extraitallpatchinbatch(allpatch,inputs):\n",
        "  for i in range(inputs.shape[0]):\n",
        "      extractallpatch(allpatch,inputs[i][0].cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H3CXh6D_KAO"
      },
      "source": [
        "**Q6 (facile)** : écrivez une fonction qui prend une liste contenant des entiers de 0 à 512 et qui retourne un histogramme de taille 512 avec h[i] le nombre de i dans la liste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K-rPU0oAUoT"
      },
      "source": [
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5PcoVeWAhmB"
      },
      "source": [
        "**Q7 facile :** écrire une fonction qui trie les indices d'un tableau en fonction des valeurs associées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABiuLW2kAsFo"
      },
      "source": [
        "\n",
        "print(\"TODO\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kd4iBZBZMGt"
      },
      "source": [
        "On va visualiser des \"classes de patchs\" **Attention** rien à voir avec la classe de l'image chat/chien -- on parle bien de la classe du patch vis à vis des K moyennes.\n",
        "\n",
        "Seulement, les classes les plus communes sont probablement justes des patchs tout noir ou tout blanc, ils contiennent peu d'information...\n",
        "d'un autre coté, si un groupe de patch contient 0 patch il n'est pas intéressant non plus...\n",
        "\n",
        "Le code suivant récupère 3 indices contenant au moins 64 éléments sans qu'ils soient juste à coté..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M4_8J74Z_Dw"
      },
      "source": [
        "def get3index(histo):\n",
        "  tmp = [(histo[i],i) for i in range(len(histo))]\n",
        "  tmp = sorted(tmp)\n",
        "  i = 0\n",
        "  while tmp[i][0]<64:\n",
        "    i+=1\n",
        "  return tmp[i][1],tmp[i+4][1],tmp[i+8][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjYSI67oICOK"
      },
      "source": [
        "**Q8 (moyen)** : visualiser des patchs d'un même centroide (disons correspondant à 3 centres comme ci dessus)\n",
        "\n",
        "*regarder l'exemple donnée dans la doc de scikit -- il vous permet de voir comment avoir le label associé à un patch*\n",
        "\n",
        "*ATTENTION 1 seul \"show64patch\" par case de notebook*\n",
        "\n",
        "le résultat des kmeans vous parait il pertinent ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOY5DzQmIurp"
      },
      "source": [
        "\n",
        "sample = next(iter(trainloader))[0]\n",
        "tmp = []\n",
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "267BbgCkcMKx"
      },
      "source": [
        "\n",
        "print(\"TODO\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtRDIVnVcNru"
      },
      "source": [
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYQNyKpJVdQT"
      },
      "source": [
        "**Q9 (moyen)** : écrire une fonction qui prend 1 image et produit l'histogramme associé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Ys7PxCWLF3"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNWsXptRI4V5"
      },
      "source": [
        "## Classification\n",
        "\n",
        "**Q BONUS (pas si dur mais à la limite des moyens de calcul)** : parcourir l'ensemble du dataset de train, produire et stocker l'ensemble des histogrammes, puis apprendre un MLP (2 couches) ou arbre ou SVM sur ces histogrammes -> utiliser plutôt des classifiers scikit learn \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
        "\n",
        "https://scikit-learn.org/stable/modules/tree.html#classification\n",
        "\n",
        "https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification\n",
        "\n",
        "\n",
        "Puis utiliser ce classifier sur les données de test -- (qu'il convient d'encoder au préalable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRmPiA6pUg7O"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "===========================================================================\n",
        "\n",
        "## Auto encodage\n",
        "\n",
        "On va auto encoder les images - donc on va optimiser un modèle à regresser la donnée elle même\n",
        "\n",
        "-> il n'y a donc que du \"x\" et pas de \"y\" (ce qui est normal pour ce TP sur le non supervisée)\n",
        "\n",
        "voilà donc des fonctions \"apprentissage/test\" mais adapté au non supervisé"
      ],
      "metadata": {
        "id": "FMBFX_DOiaK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def compute_L1(batchprovider, net):\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        net = net.cuda()\n",
        "        nb, L1 = 0, 0\n",
        "        for x, _ in batchprovider:\n",
        "            x = x.cuda()\n",
        "            z, _ = net(x)\n",
        "\n",
        "            L1 += (x - z).abs().sum()\n",
        "            nb += x.shape[0]\n",
        "    return L1, nb\n",
        "\n",
        "\n",
        "def training_epoch(batchprovider, net, lr):\n",
        "    net.train()\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    meanloss = 0\n",
        "    nb, L1 = 0, 0\n",
        "    for i, (x, _) in enumerate(batchprovider):\n",
        "        x = x.cuda()\n",
        "        z, _ = net(x)\n",
        "\n",
        "        loss = (x - z).abs().sum()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            meanloss += loss.clone().cpu().numpy()\n",
        "            L1 += loss.clone().cpu().numpy()\n",
        "            nb += x.shape[0]\n",
        "            if i % 50 == 49:\n",
        "                print(\"loss=\", meanloss / 50)\n",
        "                meanloss = 0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), 3)\n",
        "        optimizer.step()\n",
        "\n",
        "    return L1, nb\n"
      ],
      "metadata": {
        "id": "wSc7VPsYiewu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Par contre, ici le réseau ne doit pas prédire une classe mais bien produire une image, il faut donc écrire un réseau à la main qui fait ce type de tache"
      ],
      "metadata": {
        "id": "nUXvxCBgjjQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MyAutoencoder(torch.nn.Module):\n",
        "    def __init__(self, latent_space=16):\n",
        "        super(MyAutoencoder, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=5, padding=2)\n",
        "        self.conv2 = torch.nn.Conv2d(16, 64, kernel_size=5, padding=2)\n",
        "        self.l1 = torch.nn.Linear(64 * 7 * 7, latent_space)\n",
        "\n",
        "        self.d1 = torch.nn.Linear(latent_space, 512)\n",
        "        self.d2 = torch.nn.Linear(512, 512)\n",
        "        self.d3 = torch.nn.Linear(512, 7 * 7 * 64)\n",
        "        self.convd1 = torch.nn.Conv2d(64, 16, kernel_size=5, padding=2)\n",
        "        self.convd2 = torch.nn.Conv2d(16, 1, kernel_size=5, padding=2)\n",
        "\n",
        "        self.tmp = torch.nn.AdaptiveAvgPool2d((14, 14))\n",
        "        self.tmp2 = torch.nn.AdaptiveAvgPool2d((28, 28))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.leaky_relu(self.conv1(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = torch.nn.functional.max_pool2d(self.conv2(x), kernel_size=2, stride=2)\n",
        "        x = x.view(x.shape[0], 64 * 7 * 7)\n",
        "\n",
        "        code = torch.nn.functional.sigmoid(self.l1(x) * 100) * 10\n",
        "\n",
        "        x = torch.nn.functional.leaky_relu(self.d1(code))\n",
        "        x = torch.nn.functional.relu(self.d2(x))\n",
        "        x = torch.nn.functional.relu(self.d3(x))\n",
        "        x = x.view(x.shape[0], 64, 7, 7)\n",
        "\n",
        "        x = torch.nn.functional.leaky_relu(self.convd1(self.tmp(x)))\n",
        "        x = torch.nn.functional.sigmoid(self.convd2(self.tmp2(x)) * 100)\n",
        "\n",
        "        return x, code\n"
      ],
      "metadata": {
        "id": "sdfmmEF3jFgj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut maintenant appliquer ce réseau à MNIST"
      ],
      "metadata": {
        "id": "-YJKAtqOj86V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "net = MyAutoencoder()\n",
        "net = net.cuda()\n",
        "\n",
        "print(\"load data\")\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root=\"build\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "testset = torchvision.datasets.MNIST(\n",
        "    root=\"build\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "IYb-wAdXmBLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"train the model on the data\")\n",
        "\n",
        "for epoch in range(8):\n",
        "    print(\"epoch\", epoch)\n",
        "    L1, nb = training_epoch(trainloader, net, 0.00001)\n",
        "    print(\"train L1\", L1 / nb)\n",
        "\n",
        "print(\"eval model\")\n",
        "L1, nb = compute_L1(testloader, net)\n",
        "print(\"test L1\", L1 / nb)\n"
      ],
      "metadata": {
        "id": "0mbHHy1HkBEx",
        "outputId": "d62af50e-20c7-4fde-a63e-88a494593640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data\n",
            "train the model on the data\n",
            "epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss= 13499.38744140625\n",
            "loss= 12457.26837890625\n",
            "loss= 11487.30484375\n",
            "loss= 10595.5625\n",
            "loss= 9999.4964453125\n",
            "loss= 9523.31490234375\n",
            "loss= 9127.48275390625\n",
            "loss= 8729.0262109375\n",
            "loss= 8491.223916015624\n",
            "train L1 80.86031052246094\n",
            "epoch 1\n",
            "loss= 8217.725078125\n",
            "loss= 8090.51083984375\n",
            "loss= 8026.642744140625\n",
            "loss= 7934.1998828125\n",
            "loss= 7831.10419921875\n",
            "loss= 7802.143623046875\n",
            "loss= 7660.40333984375\n",
            "loss= 7624.09861328125\n",
            "loss= 7576.137021484375\n",
            "train L1 61.30629036458333\n",
            "epoch 2\n",
            "loss= 7495.608525390625\n",
            "loss= 7456.249453125\n",
            "loss= 7403.76921875\n",
            "loss= 7347.797177734375\n",
            "loss= 7286.288369140625\n",
            "loss= 7249.278828125\n",
            "loss= 7230.968505859375\n",
            "loss= 7148.968642578125\n",
            "loss= 7100.6816796875\n",
            "train L1 56.9961411702474\n",
            "epoch 3\n",
            "loss= 7083.01490234375\n",
            "loss= 7022.91845703125\n",
            "loss= 7053.47783203125\n",
            "loss= 7000.287236328125\n",
            "loss= 6949.062197265625\n",
            "loss= 6907.069423828125\n",
            "loss= 6900.790703125\n",
            "loss= 6860.770625\n",
            "loss= 6792.79177734375\n",
            "train L1 54.27356276855469\n",
            "epoch 4\n",
            "loss= 6801.295791015625\n",
            "loss= 6755.355693359375\n",
            "loss= 6738.73546875\n",
            "loss= 6674.2466796875\n",
            "loss= 6671.62462890625\n",
            "loss= 6613.59248046875\n",
            "loss= 6631.888916015625\n",
            "loss= 6648.221875\n",
            "loss= 6591.331474609375\n",
            "train L1 52.15117258300781\n",
            "epoch 5\n",
            "loss= 6487.961806640625\n",
            "loss= 6537.101015625\n",
            "loss= 6457.44271484375\n",
            "loss= 6483.734228515625\n",
            "loss= 6452.128583984375\n",
            "loss= 6442.135830078125\n",
            "loss= 6445.578671875\n",
            "loss= 6399.555048828125\n",
            "loss= 6385.532177734375\n",
            "train L1 50.37699971516927\n",
            "epoch 6\n",
            "loss= 6333.43734375\n",
            "loss= 6266.497666015625\n",
            "loss= 6331.6725390625\n",
            "loss= 6220.15525390625\n",
            "loss= 6272.302822265625\n",
            "loss= 6271.212998046875\n",
            "loss= 6200.37546875\n",
            "loss= 6181.26353515625\n",
            "loss= 6202.291123046875\n",
            "train L1 48.827913346354165\n",
            "epoch 7\n",
            "loss= 6144.604169921875\n",
            "loss= 6185.699716796875\n",
            "loss= 6117.04267578125\n",
            "loss= 6120.72990234375\n",
            "loss= 6072.586123046875\n",
            "loss= 6031.959873046875\n",
            "loss= 6026.158740234375\n",
            "loss= 6068.073955078125\n",
            "loss= 5964.473056640625\n",
            "train L1 47.488629760742185\n",
            "eval model\n",
            "test L1 tensor(46.7428, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1 : \n",
        "Afficher un paquet d'image\n",
        "\n",
        "Puis la sortie du réseau\n",
        "\n",
        "La forme globale est \"correctement\" reproduite alors qu'on a au coeur du réseau transformer l'image 28x28 en un vecteur de taille \"latent_space\"\n",
        "\n"
      ],
      "metadata": {
        "id": "P74wR7Qxlg27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TODO\")"
      ],
      "metadata": {
        "id": "tal-JdwXmnv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2\n",
        "\n",
        "oui mais est ce que ce n'est qu'une compression ou est ce que c'est une compression qui conserve un peu de sémantique ??\n",
        "\n",
        "pour le savoir affichons (dans l'espace) les \"CODES\" associé aus images"
      ],
      "metadata": {
        "id": "Zld1IcM7mpWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\n",
        "    \"#fff100\",\n",
        "    \"#ff8c00\",\n",
        "    \"#e81123\",\n",
        "    \"#ec008c\",\n",
        "    \"#68217a\",\n",
        "    \"#00188f\",\n",
        "    \"#00bcf2\",\n",
        "    \"#00b294\",\n",
        "    \"#009e49\",\n",
        "    \"#bad80a\",\n",
        "]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "    x, y = next(iter(testloader))\n",
        "    x = x.cuda()\n",
        "    _, code = net(x)\n",
        "    code = code.cpu().numpy()\n",
        "    code *= 100\n",
        "\n",
        "    C = [colors[y[i]] for i in range(128)]\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    ax.scatter(code[:, 0], code[:, 1], c=C)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_yhovjw9nlQ1",
        "outputId": "b0af83bc-fa44-4b80-96de-340e3f7d23f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "les points sont normalements +/- regroupés par couleur - mais probablement pas suffisamment - mais c'est normal puisque l'espace latent n'est pas juste 2\n",
        "\n",
        "-> que se passe-t-il avec une espace latent de 2 ?\n",
        "(en terme d'erreur et ou de regroupement des points)"
      ],
      "metadata": {
        "id": "LS9aeC2mo6Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TODO\")"
      ],
      "metadata": {
        "id": "Vn-Jh-xEpRBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3\n",
        "\n",
        "faites grossir le réseau pour obtenir une bonne compression et un bon regroupement\n",
        "(il n'y aura pas de correction de cette question : actuellement je ne suis pas 100% sur que ce soit possible sur collab)"
      ],
      "metadata": {
        "id": "8VwFVmk5pWx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(TODO)"
      ],
      "metadata": {
        "id": "juHryoD8pta5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}