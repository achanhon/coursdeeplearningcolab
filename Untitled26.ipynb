{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLkA4qm2cW1swVs48HE/GD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o3PK7CLXiLh5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "class Game:\n",
        "  def __init__(self,other=None):\n",
        "    self.A = [(0,1),(-1,0),(1,0),(0,0),(0,2)]\n",
        "    if other is None:\n",
        "      self.t = 0\n",
        "      self.f=False\n",
        "      self.p = (1,0)\n",
        "      self.road = (torch.rand(3,100)<0.05).half()\n",
        "      self.road[:,0:2]=0\n",
        "    else:\n",
        "      self.p,self.t,self.f,self.road = other\n",
        "\n",
        "  def copy(self):\n",
        "    return Game((self.p,self.t,self.f,self.road))\n",
        "\n",
        "  def getVisibleState(self):\n",
        "    assert not self.f, print(\"get state of a final state\")\n",
        "    return (self.p[0],self.p[1]-self.t), self.road[:,self.t:self.t+7]\n",
        "\n",
        "  def getVisibleStateString(self):\n",
        "    p,road = self.getVisibleState()\n",
        "    string_parts = []\n",
        "    for r in range(3):\n",
        "      for c in range(7):\n",
        "        if road[r][c]==1:\n",
        "          string_parts.append(\"o\")\n",
        "        else:\n",
        "          string_parts.append(\" \")\n",
        "        if r==p[0] and c==p[1]:\n",
        "          string_parts[-1]=\"x\"\n",
        "      string_parts.append(\"\\n\")\n",
        "    return \"----------\\n\"+\"\".join(string_parts)+\"----------\"\n",
        "\n",
        "  def possibleAction(self,dr,dc):\n",
        "    if self.p[0]+dr<0:\n",
        "      return False\n",
        "    if self.p[0]+dr>2:\n",
        "      return False\n",
        "    if self.p[1]+dc<self.t+1:\n",
        "      return False\n",
        "    if self.p[1]+dc>self.t+5:\n",
        "      return False\n",
        "    return True\n",
        "\n",
        "  def listPossibleActions(self):\n",
        "    return [i for i in range(5) if self.possibleAction(self.A[i][0],self.A[i][1])]\n",
        "\n",
        "  def update(self,a):\n",
        "    assert not self.f, print(\"update a final state\")\n",
        "    dr,dc = self.A[a]\n",
        "    assert self.possibleAction(dr,dc), print(\"unacceptable action\")\n",
        "    p = self.p\n",
        "    if self.road[p[0]+dr][p[1]+dc]==1:\n",
        "      self.f = True\n",
        "      return -100\n",
        "    if dc==2 and self.road[p[0]][p[1]+1]==1:\n",
        "      self.f = True\n",
        "      return -100\n",
        "    self.p = (p[0]+dr,p[1]+dc)\n",
        "    self.t = self.t+1\n",
        "    if self.t==90:\n",
        "      self.f = True\n",
        "    return 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "print(\"check\")\n",
        "game = Game()\n",
        "for i in range(10):\n",
        "  if game.f:\n",
        "    break\n",
        "  print(game.getVisibleStateString())\n",
        "  a = random.choice(game.listPossibleActions())\n",
        "  game.update(a)\n",
        "  print(i,a)"
      ],
      "metadata": {
        "id": "ybLDPLasrUBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbfe47c-5cff-4253-d9fb-a7b1209d1f86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check\n",
            "----------\n",
            "       \n",
            "x      \n",
            "       \n",
            "----------\n",
            "0 0\n",
            "----------\n",
            "      o\n",
            "x      \n",
            "       \n",
            "----------\n",
            "1 0\n",
            "----------\n",
            "     o \n",
            "x      \n",
            "       \n",
            "----------\n",
            "2 0\n",
            "----------\n",
            "    o  \n",
            "x      \n",
            "       \n",
            "----------\n",
            "3 4\n",
            "----------\n",
            "   o   \n",
            " x     \n",
            "       \n",
            "----------\n",
            "4 1\n",
            "----------\n",
            "x o    \n",
            "       \n",
            "       \n",
            "----------\n",
            "5 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RL,self).__init__()\n",
        "\n",
        "    self.l1 = torch.nn.Conv2d(2,8,kernel_size=3,padding=1)\n",
        "    self.l2 = torch.nn.Conv2d(10,32,kernel_size=3,padding=1)\n",
        "    self.l3 = torch.nn.Conv2d(34,64,kernel_size=(3,7))\n",
        "    self.f = torch.nn.Linear(64,5)\n",
        "\n",
        "  def forward(self,x):\n",
        "    z = torch.nn.functional.leaky_relu(self.l1(x))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l2(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l3(z))\n",
        "    z = z.view(z.shape[0],64)\n",
        "    return self.f(z)\n",
        "\n",
        "  def toTensor(self,x):\n",
        "    z = torch.zeros(2,3,7)\n",
        "    p,road = x\n",
        "    z[0]=road\n",
        "    z[1][p[0]][p[1]]=1\n",
        "    return z\n",
        "\n",
        "  def toTensorS(self,X):\n",
        "    Z = torch.zeros(len(X),2,3,7)\n",
        "    F = torch.ones(len(X))\n",
        "    for i in range(len(X)):\n",
        "      if X[i] is not None:\n",
        "        Z[i] = self.toTensor(X[i])\n",
        "      else:\n",
        "        F[i]=0\n",
        "    return Z,F\n",
        "\n",
        "  def Q(self,X):\n",
        "    Z,F = self.toTensorS(X)\n",
        "    q,_ = self.forward(Z.cuda()).max(1)\n",
        "    return q*F.cuda()\n",
        "\n",
        "  def Qa(self,X,a):\n",
        "    Z,_ = self.toTensorS(X)\n",
        "    q = self.forward(Z.cuda())\n",
        "    A = torch.zeros(len(X),5)\n",
        "    for i in range(len(X)):\n",
        "      A[i][a[i]]=1\n",
        "    return (q*A.cuda()).sum(1)\n",
        "\n",
        "\n",
        "  def policy(self,x,allowed):\n",
        "    p = self.forward(self.toTensor(x).unsqueeze(0))[0]\n",
        "    assert p.shape[0]==5\n",
        "    f = torch.ones(5)\n",
        "    for i in allowed:\n",
        "      f[i]=0\n",
        "    p = torch.nn.functional.softmax(p - 50*f,0)\n",
        "    a = torch.multinomial(p, 1).item()\n",
        "    if a in allowed:\n",
        "      return a\n",
        "    else:\n",
        "      print(\"???\")\n",
        "      return random.choice(game.listPossibleActions())\n"
      ],
      "metadata": {
        "id": "spOTFDbmz8L1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explore(agent, buffer, nbruns):\n",
        "    agent.cpu()\n",
        "    averagetotalreward = 0\n",
        "    for i in range(nbruns):\n",
        "        totalreward = 0\n",
        "        game = Game()\n",
        "        for j in range(1000):\n",
        "            x = game.getVisibleState()\n",
        "            a = agent.policy(x,game.listPossibleActions())\n",
        "            r = game.update(a)\n",
        "            totalreward = totalreward + r\n",
        "            if game.f:\n",
        "              buffer.append((x, a, r, None))\n",
        "              break\n",
        "            else:\n",
        "              buffer.append((x, a, r, game.getVisibleState()))\n",
        "        averagetotalreward = averagetotalreward + totalreward\n",
        "    return averagetotalreward / nbruns\n",
        "\n",
        "\n",
        "def training(agent, buffer, nbsteps,verbose):\n",
        "    lr = 0.0001\n",
        "    gamma=0.9\n",
        "    agent.cuda()\n",
        "    optimizer = torch.optim.Adam(agent.parameters(), lr=lr)\n",
        "\n",
        "    buffercopy = []\n",
        "    random.shuffle(buffer)\n",
        "    for step in range(nbsteps):\n",
        "        if len(buffer)<64:\n",
        "          break\n",
        "\n",
        "        X, A, R, XX = [],[],torch.zeros(64).cuda(),[]\n",
        "        for i in range(64):\n",
        "          x, a, r, xx = buffer.pop()\n",
        "          X.append(x)\n",
        "          A.append(a)\n",
        "          R[i]=r\n",
        "          XX.append(xx)\n",
        "          buffercopy.append((x, a, r, xx))\n",
        "\n",
        "        Qa = agent.Qa(X,A)\n",
        "        Q = agent.Q(XX)\n",
        "        assert Q.shape==Qa.shape\n",
        "        assert Q.shape==R.shape\n",
        "\n",
        "        tmp = gamma*Q+R.cuda()-Qa\n",
        "        tmp = torch.min(tmp*tmp,tmp.abs())\n",
        "        loss = tmp.sum()\n",
        "\n",
        "        if step % 20 == 19 and verbose:\n",
        "            print(\"\\t\", step, loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(agent.parameters(), 10)\n",
        "        optimizer.step()\n",
        "\n",
        "    return buffercopy+buffer"
      ],
      "metadata": {
        "id": "cWHMjolM6jz-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = []\n",
        "agent = RL()\n",
        "score = explore(agent, buffer, 100) #warmup\n",
        "for i in range(1000):\n",
        "  score = explore(agent, buffer, 10)\n",
        "  if i%3==0:\n",
        "      print(i, \"score\",score, len(buffer))\n",
        "  buffer = training(agent, buffer, 100, i%3==0)\n",
        "  if len(buffer)>100000:\n",
        "    random.shuffle(buffer)\n",
        "    buffer = buffer[0:100000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nXskcUYqeBdV",
        "outputId": "7ce4fc29-6df2-4ad1-dc08-5cde32a3aa44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 score -85.7 1729\n",
            "\t 19 tensor(658.6105, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "3 score -79.7 2236\n",
            "\t 19 tensor(261.3740, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "6 score -81.8 2726\n",
            "\t 19 tensor(656.5745, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(457.0306, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "9 score -89.5 3282\n",
            "\t 19 tensor(255.1986, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(456.6625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "12 score -75.4 3838\n",
            "\t 19 tensor(348.7864, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(254.1586, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "15 score -92.4 4177\n",
            "\t 19 tensor(553.7122, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(455.9207, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(346.2603, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "18 score -85.0 4670\n",
            "\t 19 tensor(643.2094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(250.0684, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(541.6766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "21 score -61.3 5273\n",
            "\t 19 tensor(746.2580, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(436.8594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(539.2518, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(337.7655, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "24 score -87.8 5655\n",
            "\t 19 tensor(228.6121, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(222.4142, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(437.1843, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(429.3185, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "27 score -90.4 6143\n",
            "\t 19 tensor(219.6715, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(327.8236, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(222.0827, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(537.9321, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "30 score -83.6 6663\n",
            "\t 19 tensor(324.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(12.5892, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(221.8446, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(426.4185, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(329.8531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "33 score -85.8 7150\n",
            "\t 19 tensor(325.7668, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(629.3814, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(222.5308, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(634.7028, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(127.2260, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "36 score -84.0 7730\n",
            "\t 19 tensor(533.7560, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(729.8181, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(219.0622, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(225.6316, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(326.5005, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "39 score -78.0 8387\n",
            "\t 19 tensor(118.4366, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(314.6898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(224.3495, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(118.6383, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(422.1696, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "42 score -82.2 8952\n",
            "\t 19 tensor(328.7466, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(11.7456, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(217.5482, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(436.6807, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(932.8110, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "45 score -77.8 9497\n",
            "\t 19 tensor(435.1282, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(419.4553, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(225.0206, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(739.8405, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(318.6252, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "48 score -87.2 10071\n",
            "\t 19 tensor(121.0967, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(126.0457, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(425.1745, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(520.9323, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(425.5823, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "51 score -82.8 10525\n",
            "\t 19 tensor(525.6378, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(433.3571, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(733.8082, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 79 tensor(226.7970, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 99 tensor(526.4471, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "54 score -89.1 10929\n",
            "\t 19 tensor(433.1703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 39 tensor(320.3140, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "\t 59 tensor(408.0435, device='cuda:0', grad_fn=<SumBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3814dacfa8fe>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-660843cf332d>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(agent, buffer, nbsteps, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mQa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mQa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5d7121d9b541>\u001b[0m in \u001b[0;36mQ\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoTensorS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5d7121d9b541>\u001b[0m in \u001b[0;36mtoTensorS\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}