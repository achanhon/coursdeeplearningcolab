{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqVZU2fbDtA+8YXKhc2nWy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o3PK7CLXiLh5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "class Game:\n",
        "  def __init__(self,other=None):\n",
        "    self.A = [(0,1),(-1,0),(1,0),(0,0),(0,2)]\n",
        "    if other is None:\n",
        "      self.t = 0\n",
        "      self.f=False\n",
        "      self.p = (1,0)\n",
        "      self.road = (torch.rand(3,100)<0.05).half()\n",
        "      self.road[:,0:2]=0\n",
        "    else:\n",
        "      self.p,self.t,self.f,self.road = other\n",
        "\n",
        "  def copy(self):\n",
        "    return Game((self.p,self.t,self.f,self.road))\n",
        "\n",
        "  def getVisibleState(self):\n",
        "    assert not self.f, print(\"get state of a final state\")\n",
        "    return (self.p[0],self.p[1]-self.t), self.road[:,self.t:self.t+7]\n",
        "\n",
        "  def getVisibleStateString(self):\n",
        "    p,road = self.getVisibleState()\n",
        "    string_parts = []\n",
        "    for r in range(3):\n",
        "      for c in range(7):\n",
        "        if road[r][c]==1:\n",
        "          string_parts.append(\"o\")\n",
        "        else:\n",
        "          string_parts.append(\" \")\n",
        "        if r==p[0] and c==p[1]:\n",
        "          string_parts[-1]=\"x\"\n",
        "      string_parts.append(\"\\n\")\n",
        "    return \"----------\\n\"+\"\".join(string_parts)+\"----------\"\n",
        "\n",
        "  def possibleAction(self,dr,dc):\n",
        "    if self.p[0]+dr<0:\n",
        "      return False\n",
        "    if self.p[0]+dr>2:\n",
        "      return False\n",
        "    if self.p[1]+dc<self.t+1:\n",
        "      return False\n",
        "    if self.p[1]+dc>self.t+5:\n",
        "      return False\n",
        "    return True\n",
        "\n",
        "  def listPossibleActions(self):\n",
        "    return [i for i in range(5) if self.possibleAction(self.A[i][0],self.A[i][1])]\n",
        "\n",
        "  def update(self,a):\n",
        "    assert not self.f, print(\"update a final state\")\n",
        "    dr,dc = self.A[a]\n",
        "    assert self.possibleAction(dr,dc), print(\"unacceptable action\")\n",
        "    p = self.p\n",
        "    if self.road[p[0]+dr][p[1]+dc]==1:\n",
        "      self.f = True\n",
        "      return -100\n",
        "    if dc==2 and self.road[p[0]][p[1]+1]==1:\n",
        "      self.f = True\n",
        "      return -100\n",
        "    self.p = (p[0]+dr,p[1]+dc)\n",
        "    self.t = self.t+1\n",
        "    if self.t==90:\n",
        "      self.f = True\n",
        "      return 100\n",
        "    else:\n",
        "      return 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "print(\"check\")\n",
        "game = Game()\n",
        "for i in range(10):\n",
        "  if game.f:\n",
        "    break\n",
        "  print(game.getVisibleStateString())\n",
        "  a = random.choice(game.listPossibleActions())\n",
        "  game.update(a)\n",
        "  print(i,a)"
      ],
      "metadata": {
        "id": "ybLDPLasrUBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc1da6a-917a-41b1-f85d-f464c16af66e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check\n",
            "----------\n",
            "       \n",
            "x      \n",
            "       \n",
            "----------\n",
            "0 0\n",
            "----------\n",
            "       \n",
            "x      \n",
            "       \n",
            "----------\n",
            "1 0\n",
            "----------\n",
            "       \n",
            "x      \n",
            "       \n",
            "----------\n",
            "2 0\n",
            "----------\n",
            "      o\n",
            "x     o\n",
            "       \n",
            "----------\n",
            "3 0\n",
            "----------\n",
            "     o \n",
            "x    o \n",
            "       \n",
            "----------\n",
            "4 0\n",
            "----------\n",
            "    o  \n",
            "x   o  \n",
            "       \n",
            "----------\n",
            "5 0\n",
            "----------\n",
            "   o   \n",
            "x  o   \n",
            "      o\n",
            "----------\n",
            "6 0\n",
            "----------\n",
            "  o    \n",
            "x o    \n",
            "     o \n",
            "----------\n",
            "7 0\n",
            "----------\n",
            " o     \n",
            "xo     \n",
            "    o  \n",
            "----------\n",
            "8 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RL,self).__init__()\n",
        "\n",
        "    self.l1 = torch.nn.Conv2d(2,8,kernel_size=3,padding=1)\n",
        "    self.l2 = torch.nn.Conv2d(10,32,kernel_size=3,padding=1)\n",
        "    self.l3 = torch.nn.Conv2d(34,64,kernel_size=(3,7))\n",
        "    self.f = torch.nn.Linear(64,5)\n",
        "\n",
        "  def forward(self,x):\n",
        "    z = torch.nn.functional.leaky_relu(self.l1(x))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l2(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l3(z))\n",
        "    z = z.view(z.shape[0],64)\n",
        "    return self.f(z)\n",
        "\n",
        "  def toTensor(self,x):\n",
        "    z = torch.zeros(2,3,7)\n",
        "    p,road = x\n",
        "    z[0]=road\n",
        "    z[1][p[0]][p[1]]=1\n",
        "    return z\n",
        "\n",
        "  def toTensorS(self,X):\n",
        "    Z = torch.zeros(len(X),2,3,7)\n",
        "    F = torch.ones(len(X))\n",
        "    for i in range(len(X)):\n",
        "      if X[i] is not None:\n",
        "        Z[i] = self.toTensor(X[i])\n",
        "      else:\n",
        "        F[i]=0\n",
        "    return Z,F\n",
        "\n",
        "  def Q(self,X):\n",
        "    Z,F = self.toTensorS(X)\n",
        "    q,_ = self.forward(Z.cuda()).max(1)\n",
        "    return q*F.cuda()\n",
        "\n",
        "  def Qa(self,X,a):\n",
        "    Z,_ = self.toTensorS(X)\n",
        "    q = self.forward(Z.cuda())\n",
        "    A = torch.zeros(len(X),5)\n",
        "    for i in range(len(X)):\n",
        "      A[i][a[i]]=1\n",
        "    return (q*A.cuda()).sum(1)\n",
        "\n",
        "\n",
        "  def policy(self,x,allowed):\n",
        "    p = self.forward(self.toTensor(x).unsqueeze(0))[0]\n",
        "    assert p.shape[0]==5\n",
        "    f = torch.ones(5)\n",
        "    for i in allowed:\n",
        "      f[i]=0\n",
        "    p = torch.nn.functional.softmax(p - 50*f,0)\n",
        "    a = torch.multinomial(p, 1).item()\n",
        "    if a in allowed:\n",
        "      return a\n",
        "    else:\n",
        "      print(\"???\")\n",
        "      return random.choice(game.listPossibleActions())\n"
      ],
      "metadata": {
        "id": "spOTFDbmz8L1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explore(agent, buffer, nbruns):\n",
        "    agent.cpu()\n",
        "    averagetotalreward = 0\n",
        "    for i in range(nbruns):\n",
        "        totalreward = 0\n",
        "        game = Game()\n",
        "        for j in range(1000):\n",
        "            x = game.getVisibleState()\n",
        "            a = agent.policy(x,game.listPossibleActions())\n",
        "            r = game.update(a)\n",
        "            totalreward = totalreward + r\n",
        "            if game.f:\n",
        "              buffer.append((x, a, r, None))\n",
        "              break\n",
        "            else:\n",
        "              buffer.append((x, a, r, game.getVisibleState()))\n",
        "        averagetotalreward = averagetotalreward + totalreward\n",
        "    return averagetotalreward / nbruns\n",
        "\n",
        "\n",
        "def training(agent, buffer, nbsteps):\n",
        "    lr = 0.0001\n",
        "    gamma=0.9\n",
        "    agent.cuda()\n",
        "    optimizer = torch.optim.Adam(agent.parameters(), lr=lr)\n",
        "\n",
        "    buffercopy = []\n",
        "    random.shuffle(buffer)\n",
        "    for step in range(nbsteps):\n",
        "        if len(buffer)<64:\n",
        "          break\n",
        "\n",
        "        X, A, R, XX = [],[],torch.zeros(64).cuda(),[]\n",
        "        for i in range(64):\n",
        "          x, a, r, xx = buffer.pop()\n",
        "          X.append(x)\n",
        "          A.append(a)\n",
        "          R[i]=r\n",
        "          XX.append(xx)\n",
        "          buffercopy.append((x, a, r, xx))\n",
        "\n",
        "        Qa = agent.Qa(X,A)\n",
        "        Q = agent.Q(XX)\n",
        "\n",
        "        tmp = gamma*Q+r-Qa\n",
        "        tmp = torch.min(tmp*tmp,tmp.abs())\n",
        "        loss = tmp.sum()\n",
        "\n",
        "        if step % 20 == 19:\n",
        "            print(step, loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(agent.parameters(), 3)\n",
        "        optimizer.step()\n",
        "\n",
        "    return buffercopy"
      ],
      "metadata": {
        "id": "cWHMjolM6jz-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = []\n",
        "agent = RL()\n",
        "for i in range(100):\n",
        "  score = explore(agent, buffer, 64)\n",
        "  print(i, \"score\",score, len(buffer))\n",
        "  buffer = training(agent, buffer, 100)\n",
        "  if len(buffer)>100000:\n",
        "    random.shuffle(buffer)\n",
        "    buffer = buffer[0:100000]"
      ],
      "metadata": {
        "id": "nXskcUYqeBdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}