{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPadP1+M3pbLcomV9PqhXOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o3PK7CLXiLh5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "class Game:\n",
        "  def __init__(self,other=None):\n",
        "    self.A = [(0,1),(-1,0),(1,0),(0,0),(0,2)]\n",
        "    if other is None:\n",
        "      self.t = 0\n",
        "      self.f=False\n",
        "      self.p = (1,0)\n",
        "      self.road = (torch.rand(3,100)<0.05).half()\n",
        "      self.road[:,0:2]=0\n",
        "    else:\n",
        "      self.p,self.t,self.f,self.road = other\n",
        "\n",
        "  def copy(self):\n",
        "    return Game((self.p,self.t,self.f,self.road))\n",
        "\n",
        "  def getVisibleState(self):\n",
        "    assert not self.f, print(\"get state of a final state\")\n",
        "    return (self.p[0],self.p[1]-self.t), self.road[:,self.t:self.t+7]\n",
        "\n",
        "  def getVisibleStateString(self):\n",
        "    p,road = self.getVisibleState()\n",
        "    string_parts = []\n",
        "    for r in range(3):\n",
        "      for c in range(7):\n",
        "        if road[r][c]==1:\n",
        "          string_parts.append(\"o\")\n",
        "        else:\n",
        "          string_parts.append(\" \")\n",
        "        if r==p[0] and c==p[1]:\n",
        "          string_parts[-1]=\"x\"\n",
        "      string_parts.append(\"\\n\")\n",
        "    return \"----------\\n\"+\"\".join(string_parts)+\"----------\"\n",
        "\n",
        "  def possibleAction(self,dr,dc):\n",
        "    if self.p[0]+dr<0:\n",
        "      return False\n",
        "    if self.p[0]+dr>2:\n",
        "      return False\n",
        "    if self.p[1]+dc<self.t+1:\n",
        "      return False\n",
        "    if self.p[1]+dc>self.t+5:\n",
        "      return False\n",
        "    return True\n",
        "\n",
        "  def listPossibleActions(self):\n",
        "    return [i for i in range(5) if self.possibleAction(self.A[i][0],self.A[i][1])]\n",
        "\n",
        "  def update(self,a):\n",
        "    assert not self.f, print(\"update a final state\")\n",
        "    dr,dc = self.A[a]\n",
        "    assert self.possibleAction(dr,dc), print(\"unacceptable action\")\n",
        "    p = self.p\n",
        "    if self.road[p[0]+dr][p[1]+dc]==1:\n",
        "      self.f = True\n",
        "      return -10\n",
        "    if dc==2 and self.road[p[0]][p[1]+1]==1:\n",
        "      self.f = True\n",
        "      return -10\n",
        "    self.p = (p[0]+dr,p[1]+dc)\n",
        "    self.t = self.t+1\n",
        "    if self.t==90:\n",
        "      self.f = True\n",
        "    return 0.12\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "print(\"check\")\n",
        "game = Game()\n",
        "for i in range(10):\n",
        "  if game.f:\n",
        "    break\n",
        "  print(game.getVisibleStateString())\n",
        "  a = random.choice(game.listPossibleActions())\n",
        "  game.update(a)\n",
        "  print(i,a)"
      ],
      "metadata": {
        "id": "ybLDPLasrUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RL(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RL,self).__init__()\n",
        "\n",
        "    self.l1 = torch.nn.Conv2d(2,8,kernel_size=3,padding=1)\n",
        "    self.l2 = torch.nn.Conv2d(10,16,kernel_size=3,padding=1)\n",
        "    self.l3 = torch.nn.Conv2d(18,32,kernel_size=(3,7))\n",
        "    self.l4 = torch.nn.Conv2d(18,32,kernel_size=1)\n",
        "    self.f = torch.nn.Linear(64,5)\n",
        "\n",
        "  def forward(self,x):\n",
        "    z = torch.nn.functional.leaky_relu(self.l1(x))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z = torch.nn.functional.leaky_relu(self.l2(z))\n",
        "    z = torch.cat([z,x],dim=1)\n",
        "    z1 = torch.nn.functional.leaky_relu(self.l3(z))\n",
        "    z1 = z1.view(z.shape[0],32)\n",
        "    z2 = torch.nn.functional.max_pool2d(self.l4(z),kernel_size=(3,7))\n",
        "    z2 = z2.view(z.shape[0],32)\n",
        "    z = torch.cat([z1,z2],dim=1)\n",
        "    return self.f(z)\n",
        "\n",
        "  def toTensor(self,x):\n",
        "    z = torch.zeros(2,3,7)\n",
        "    p,road = x\n",
        "    z[0]=road\n",
        "    z[1][p[0]][p[1]]=1\n",
        "    return z\n",
        "\n",
        "  def toTensorS(self,X):\n",
        "    Z = torch.zeros(len(X),2,3,7)\n",
        "    F = torch.ones(len(X))\n",
        "    for i in range(len(X)):\n",
        "      if X[i] is not None:\n",
        "        Z[i] = self.toTensor(X[i])\n",
        "      else:\n",
        "        F[i]=0\n",
        "    return Z,F\n",
        "\n",
        "  def Q(self,X):\n",
        "    Z,F = self.toTensorS(X)\n",
        "    if torch.cuda.is_available():\n",
        "      q,_ = self.forward(Z.cuda().float()).max(1)\n",
        "      return q*F.cuda()\n",
        "    else:\n",
        "      q,_ = self.forward(Z.float()).max(1)\n",
        "      return q*F\n",
        "\n",
        "\n",
        "  def Qa(self,X,a):\n",
        "    Z,_ = self.toTensorS(X)\n",
        "    A = torch.zeros(len(X),5)\n",
        "    for i in range(len(X)):\n",
        "      A[i][a[i]]=1\n",
        "    if torch.cuda.is_available():\n",
        "      q = self.forward(Z.cuda().float())\n",
        "      return (q*A.cuda()).sum(1)\n",
        "    else:\n",
        "      q = self.forward(Z.float())\n",
        "      return (q*A).sum(1)\n",
        "\n",
        "\n",
        "\n",
        "  def policy(self,x,allowed):\n",
        "    x = self.toTensor(x).unsqueeze(0)\n",
        "    p = self.forward(x)[0]\n",
        "    assert p.shape[0]==5\n",
        "    f = torch.ones(5)\n",
        "    for i in allowed:\n",
        "      f[i]=0\n",
        "    p = torch.nn.functional.softmax(p - 50*f,0)\n",
        "    a = torch.multinomial(p, 1).item()\n",
        "    if a in allowed:\n",
        "      return a\n",
        "    else:\n",
        "      print(\"???\")\n",
        "      return random.choice(game.listPossibleActions())\n"
      ],
      "metadata": {
        "id": "spOTFDbmz8L1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explore(agent, buffer, nbruns):\n",
        "    agent.cpu()\n",
        "    averagetotalreward = 0\n",
        "    for i in range(nbruns):\n",
        "        totalreward = 0\n",
        "        game = Game()\n",
        "        for j in range(1000):\n",
        "            x = game.getVisibleState()\n",
        "            a = agent.policy(x,game.listPossibleActions())\n",
        "            r = game.update(a)\n",
        "            totalreward = totalreward + r\n",
        "            if game.f:\n",
        "              buffer.append((x, a, r, None))\n",
        "              break\n",
        "            else:\n",
        "              buffer.append((x, a, r, game.getVisibleState()))\n",
        "        averagetotalreward = averagetotalreward + totalreward\n",
        "    return averagetotalreward / nbruns\n",
        "\n",
        "\n",
        "def training(agent, buffer, nbsteps,verbose):\n",
        "    lr = 0.0001\n",
        "    gamma=0.9\n",
        "    if torch.cuda.is_available():\n",
        "      agent.cuda()\n",
        "    optimizer = torch.optim.Adam(agent.parameters(), lr=lr)\n",
        "\n",
        "    buffercopy = []\n",
        "    random.shuffle(buffer)\n",
        "    for step in range(nbsteps):\n",
        "        if len(buffer)<64:\n",
        "          break\n",
        "\n",
        "        X, A, R, XX = [],[],torch.zeros(64),[]\n",
        "        for i in range(64):\n",
        "          x, a, r, xx = buffer.pop()\n",
        "          X.append(x)\n",
        "          A.append(a)\n",
        "          R[i]=r\n",
        "          XX.append(xx)\n",
        "          buffercopy.append((x, a, r, xx))\n",
        "\n",
        "        Qa = agent.Qa(X,A)\n",
        "        Q = agent.Q(XX)\n",
        "        assert Q.shape==Qa.shape\n",
        "        assert Q.shape==R.shape\n",
        "        if torch.cuda.is_available():\n",
        "          R = R.cuda()\n",
        "\n",
        "        tmp = gamma*Q+R-Qa\n",
        "        tmp = torch.min(tmp*tmp,tmp.abs())\n",
        "        loss = tmp.sum()\n",
        "\n",
        "        if step % 20 == 19 and verbose:\n",
        "            print(\"\\t\", step, loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(agent.parameters(), 10)\n",
        "        optimizer.step()\n",
        "\n",
        "    return buffercopy+buffer"
      ],
      "metadata": {
        "id": "cWHMjolM6jz-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = []\n",
        "agent = RL()\n",
        "score = explore(agent, buffer, 100) #warmup\n",
        "for i in range(200):\n",
        "  score = explore(agent, buffer, 10)\n",
        "  if i%6==0:\n",
        "      print(i, \"score\",score, len(buffer))\n",
        "  buffer = training(agent, buffer, 100, i%6==0)\n",
        "  if len(buffer)>100000:\n",
        "    random.shuffle(buffer)\n",
        "    buffer = buffer[0:100000]\n",
        "\n",
        "print(\"final score\", explore(agent, buffer, 1000))"
      ],
      "metadata": {
        "id": "nXskcUYqeBdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clonerl(agent):\n",
        "  with torch.no_grad():\n",
        "    out = RL()\n",
        "    out.l1.weight.data=agent.l1.weight.clone()\n",
        "    out.l1.bias.data=agent.l1.bias.clone()\n",
        "    out.l2.weight.data=agent.l2.weight.clone()\n",
        "    out.l2.bias.data=agent.l2.bias.clone()\n",
        "    out.l3.weight.data=agent.l3.weight.clone()\n",
        "    out.l3.bias.data=agent.l3.bias.clone()\n",
        "    out.l4.weight.data=agent.l4.weight.clone()\n",
        "    out.l4.bias.data=agent.l4.bias.clone()\n",
        "    out.f.weight.data=agent.f.weight.clone()\n",
        "    out.f.bias.data=agent.f.bias.clone()\n",
        "    return out\n",
        "\n",
        "buffer = []\n",
        "agent = RL()\n",
        "score = explore(agent, buffer, 100) #warmup\n",
        "for i in range(200):\n",
        "  score = explore(agent, buffer, 10)\n",
        "  if i%6==0:\n",
        "      print(i, \"score\",score, len(buffer))\n",
        "\n",
        "  agentbis = clonerl(agent)\n",
        "  buffer = training(agentbis, buffer, 100, i%6==0)\n",
        "  agentbis.cpu()\n",
        "  with torch.no_grad():\n",
        "    agent.l1.weight.data=(agent.l1.weight.clone()+agentbis.l1.weight)/2\n",
        "    agent.l1.bias.data=(agent.l1.bias.clone()+agentbis.l1.bias)/2\n",
        "    agent.l2.weight.data=(agent.l2.weight.clone()+agentbis.l2.weight)/2\n",
        "    agent.l2.bias.data=(agent.l2.bias.clone()+agentbis.l2.bias)/2\n",
        "    agent.l3.weight.data=(agent.l3.weight.clone()+agentbis.l3.weight)/2\n",
        "    agent.l3.bias.data=(agent.l3.bias.clone()+agentbis.l3.bias)/2\n",
        "    agent.l4.weight.data=(agent.l4.weight.clone()+agentbis.l4.weight)/2\n",
        "    agent.l4.bias.data=(agent.l4.bias.clone()+agentbis.l4.bias)/2\n",
        "    agent.f.weight.data=(agent.f.weight.clone()+agentbis.f.weight)/2\n",
        "    agent.f.bias.data=(agent.f.bias.clone()+agentbis.f.bias)/2\n",
        "\n",
        "  if len(buffer)>100000:\n",
        "    random.shuffle(buffer)\n",
        "    buffer = buffer[0:100000]\n",
        "\n",
        "print(\"final score\", explore(agent, buffer, 1000))"
      ],
      "metadata": {
        "id": "GN5q4_JQ_kg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(agent,frozenagent, buffer, nbsteps,verbose):\n",
        "    lr = 0.0001\n",
        "    gamma=0.9\n",
        "    if torch.cuda.is_available():\n",
        "      agent.cuda()\n",
        "    optimizer = torch.optim.Adam(agent.parameters(), lr=lr)\n",
        "\n",
        "    buffercopy = []\n",
        "    random.shuffle(buffer)\n",
        "    for step in range(nbsteps):\n",
        "        if len(buffer)<64:\n",
        "          break\n",
        "\n",
        "        X, A, R, XX = [],[],torch.zeros(64),[]\n",
        "        for i in range(64):\n",
        "          x, a, r, xx = buffer.pop()\n",
        "          X.append(x)\n",
        "          A.append(a)\n",
        "          R[i]=r\n",
        "          XX.append(xx)\n",
        "          buffercopy.append((x, a, r, xx))\n",
        "\n",
        "        Qa = agent.Qa(X,A)\n",
        "        with torch.no_grad():\n",
        "          Q = frozenagent.Q(XX)\n",
        "        assert Q.shape==Qa.shape\n",
        "        assert Q.shape==R.shape\n",
        "        if torch.cuda.is_available():\n",
        "          R = R.cuda()\n",
        "\n",
        "        tmp = gamma*Q+R-Qa\n",
        "        tmp = torch.min(tmp*tmp,tmp.abs())\n",
        "        loss = tmp.sum()\n",
        "\n",
        "        if step % 20 == 19 and verbose:\n",
        "            print(\"\\t\", step, loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(agent.parameters(), 10)\n",
        "        optimizer.step()\n",
        "\n",
        "    return buffercopy+buffer"
      ],
      "metadata": {
        "id": "852tFcyFjWZm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = []\n",
        "agent = RL()\n",
        "score = explore(agent, buffer, 100) #warmup\n",
        "for i in range(200):\n",
        "  score = explore(agent, buffer, 10)\n",
        "  if i%6==0:\n",
        "      print(i, \"score\",score, len(buffer))\n",
        "\n",
        "  agentbis = clonerl(agent)\n",
        "  buffer = training(agentbis,agent, buffer, 100, i%6==0)\n",
        "  agentbis.cpu()\n",
        "  with torch.no_grad():\n",
        "    agent.l1.weight.data=(agent.l1.weight.clone()+agentbis.l1.weight)/2\n",
        "    agent.l1.bias.data=(agent.l1.bias.clone()+agentbis.l1.bias)/2\n",
        "    agent.l2.weight.data=(agent.l2.weight.clone()+agentbis.l2.weight)/2\n",
        "    agent.l2.bias.data=(agent.l2.bias.clone()+agentbis.l2.bias)/2\n",
        "    agent.l3.weight.data=(agent.l3.weight.clone()+agentbis.l3.weight)/2\n",
        "    agent.l3.bias.data=(agent.l3.bias.clone()+agentbis.l3.bias)/2\n",
        "    agent.l4.weight.data=(agent.l4.weight.clone()+agentbis.l4.weight)/2\n",
        "    agent.l4.bias.data=(agent.l4.bias.clone()+agentbis.l4.bias)/2\n",
        "    agent.f.weight.data=(agent.f.weight.clone()+agentbis.f.weight)/2\n",
        "    agent.f.bias.data=(agent.f.bias.clone()+agentbis.f.bias)/2\n",
        "\n",
        "  if len(buffer)>100000:\n",
        "    random.shuffle(buffer)\n",
        "    buffer = buffer[0:100000]\n",
        "\n",
        "print(\"final score\", explore(agent, buffer, 1000))"
      ],
      "metadata": {
        "id": "oS_bJNZFjs5g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}