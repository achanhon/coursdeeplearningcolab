{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSuKkL0DQVdrFq2HdTcp2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/introductionVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Méthode de vision par ordinateur \"traditionnelles\"\n",
        "\n",
        "## Extraction de contours"
      ],
      "metadata": {
        "id": "rX-amW26Sk8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "def show(x):\n",
        "    if len(x.shape)==2:\n",
        "        plt.imshow(x, interpolation='nearest')\n",
        "        return\n",
        "    if len(x.shape)==3:\n",
        "        visu = torch.stack([x[0],x[1],x[2]],dim=-1)\n",
        "        plt.imshow(visu.numpy(), interpolation='nearest')\n",
        "    else:\n",
        "        show(torchvision.utils.make_grid(x))\n",
        "\n",
        "def readimage(path):\n",
        "    tmp = PIL.Image.open(path)\n",
        "    x = torch.Tensor(numpy.asarray(tmp)).clone()\n",
        "    if len(x.shape)==2:\n",
        "        return x\n",
        "    else:\n",
        "        return torch.stack([x[:,:,0],x[:,:,1],x[:,:,2]],dim=0)\n",
        ""
      ],
      "metadata": {
        "id": "Ph5C1djmTiRm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://httpmail.onera.fr/5/ab54f8bf5ce3bc61fe8dda498f109b76YvVQrY/astronaut.jpg\n",
        "image = readimage(\"astronaut.jpg\")\n",
        "show(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "A1ogbMRAUMUf",
        "outputId": "8ad95889-b08f-4727-970b-2527fd8be436"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-12 16:12:05--  https://httpmail.onera.fr/5/ab54f8bf5ce3bc61fe8dda498f109b76YvVQrY/astronaut.jpg\n",
            "Resolving httpmail.onera.fr (httpmail.onera.fr)... 144.204.16.9\n",
            "Connecting to httpmail.onera.fr (httpmail.onera.fr)|144.204.16.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40344 (39K) [application/force-download]\n",
            "Saving to: ‘astronaut.jpg.1’\n",
            "\n",
            "astronaut.jpg.1     100%[===================>]  39.40K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-12 16:12:06 (282 KB/s) - ‘astronaut.jpg.1’ saved [40344/40344]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file 'astronaut.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a8559b6bbc1b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://httpmail.onera.fr/5/ab54f8bf5ce3bc61fe8dda498f109b76YvVQrY/astronaut.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astronaut.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-3b765ad69ccb>\u001b[0m in \u001b[0;36mreadimage\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'astronaut.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show(image[0])"
      ],
      "metadata": {
        "id": "zHO6J75JWkcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def sobel_filter(image):\n",
        "    \"\"\"\n",
        "    Applies a Sobel filter to a grayscale PyTorch tensor (image).\n",
        "\n",
        "    Args:\n",
        "        image (torch.Tensor): A grayscale image tensor of shape (batch_size, channels, height, width).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor of shape (batch_size, 2, height, width), where the first channel\n",
        "                      represents the horizontal gradient and the second channel represents the vertical gradient.\n",
        "    \"\"\"\n",
        "\n",
        "    if image.dim() != 4:\n",
        "        raise ValueError(\"Input image must be a 4D tensor (batch_size, channels, height, width).\")\n",
        "\n",
        "    if image.shape[1] != 1:\n",
        "        raise ValueError(\"Input image must be grayscale (single channel).\")\n",
        "\n",
        "    # Sobel filter kernels for horizontal and vertical gradients\n",
        "    sobel_x = torch.tensor([[1, 0, -1],\n",
        "                           [2, 0, -2],\n",
        "                           [1, 0, -1]], dtype=image.dtype)[:, None, ...]\n",
        "    sobel_y = torch.tensor([[1, 2, 1],\n",
        "                           [0, 0, 0],\n",
        "                           [-1, -2, -1]], dtype=image.dtype)[:, None, ...]\n",
        "\n",
        "    # Ensure kernels are on the same device as the image\n",
        "    sobel_x = sobel_x.to(image.device)\n",
        "    sobel_y = sobel_y.to(image.device)\n",
        "\n",
        "    # Apply convolution with each kernel\n",
        "    horizontal_gradients = torch.nn.functional.conv2d(image, sobel_x, padding=1)\n",
        "    vertical_gradients = torch.nn.functional.conv2d(image, sobel_y, padding=1)\n",
        "\n",
        "    # Combine gradients (optional: magnitude or direction calculation)\n",
        "    # gradients = torch.sqrt(horizontal_gradients**2 + vertical_gradients**2)  # Magnitude\n",
        "    # OR\n",
        "    # gradients = torch.atan2(vertical_gradients, horizontal_gradients)  # Direction\n",
        "\n",
        "    return torch.cat((horizontal_gradients, vertical_gradients), dim=1)\n",
        "\n",
        "# Example usage\n",
        "image = torch.randn(1, 1, 28, 28)  # Example grayscale image of size (28, 28)\n",
        "gradients = sobel_filter(image)\n",
        "print(gradients.shape)  # Output: torch.Size([1, 2, 28, 28])\n"
      ],
      "metadata": {
        "id": "SVV3mH2VS2dl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}