{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIYCAPxwOZPWSq/HY/YanU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/cnn_cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g40b8hmADuAg"
      },
      "source": [
        "TP : VGG13 sur CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw3ine_rDpvX"
      },
      "source": [
        "import torch\n",
        "\n",
        "def compute_accuracy(batchprovider,net):\n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "    net=net.cuda()\n",
        "    nb, nbOK = 0, 0\n",
        "    for x,y in batchprovider:\n",
        "      x,y = x.cuda(),y.cuda()\n",
        "      z = net(x)\n",
        "      \n",
        "      _,z = z.max(1)\n",
        "      good = (y==z).float()\n",
        "      nb+=good.shape[0]\n",
        "      nbOK+=good.sum().cpu().numpy()\n",
        "  return nbOK,nb\n",
        "\n",
        "import random\n",
        "import collections\n",
        "\n",
        "def simple_training(batchprovider,net,lr,nbepoch):\n",
        "  net.train()\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "  meanloss = collections.deque(maxlen=200)\n",
        "  for epoch in range(nbepoch):\n",
        "    print(epoch,\"/\",nbepoch)\n",
        "    nb, nbOK = 0, 0\n",
        "    for x,y in batchprovider:\n",
        "      x,y = x.cuda(),y.cuda()\n",
        "      z = net(x)\n",
        "\n",
        "      loss = criterion(z, y)\n",
        "      meanloss.append(loss.cpu().data.numpy())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(net.parameters(), 10)\n",
        "      optimizer.step()\n",
        "\n",
        "      _,z = z.max(1)\n",
        "      good = (y==z).float()\n",
        "      nb+=good.shape[0]\n",
        "      nbOK+=good.sum().cpu().numpy()\n",
        "\n",
        "      if random.randint(0, 30) == 0:\n",
        "        print(\"average loss=\", (sum(meanloss) / len(meanloss)))\n",
        "    print(\"average train accuracy\",nbOK/nb)\n",
        "    if nbOK/nb>0.98:\n",
        "      print(\"early stopping\")\n",
        "      return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MntQTF6GeoO"
      },
      "source": [
        "VGG13 et CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_NDYNEqD_s6"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "print(\"load model\")\n",
        "net = torchvision.models.vgg13(pretrained=True)\n",
        "net.avgpool = torch.nn.Identity()\n",
        "net.classifier = torch.nn.Linear(512, 10)\n",
        "net = net.cuda()\n",
        "\n",
        "print(\"load data\")\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=64, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "print(\"finetune the model on the data\")\n",
        "simple_training(trainloader,net, 0.0001,8)\n",
        "\n",
        "print(\"eval model\")\n",
        "nbok,nb = compute_accuracy(testloader,net)\n",
        "print(\"test accuracy\",nbok/nb)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}